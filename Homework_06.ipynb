{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aydanmufti/Module-7-Assignments/blob/main/Homework_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_N2ztyX4tsu"
      },
      "source": [
        "# Homework 6: N-Gram Language Models with the Brown Corpus\n",
        "\n",
        "## Due: Midnight on October 12th @ Midnight (with 2-hour grace period) and worth 85 points.\n",
        "\n",
        "## As announced, I'll not start to count late days until midnight on 10/13 (with same grace period).\n",
        "\n",
        "In this assignment you’ll practice **probabilistic language modeling (PLM)** by building N-Gram models that generate text. Along the way, you’ll develop the core pieces of a language model: estimating probabilities, calculating sentence likelihoods, and generating text with different strategies. The goal is to understand *how simple statistical models can produce coherent language*, and to explore refinements that make them more expressive.\n",
        "\n",
        "### Learning Objectives\n",
        "\n",
        "* Build and compare **unigram, bigram, and trigram** language models.\n",
        "* Calculate **word and sentence probabilities** (in log-space) and use them to measure **perplexity**.\n",
        "* Implement **probability-based generation** methods, including temperature-scaled sampling.\n",
        "* Explore **beam search** as a way to generate higher-quality sentences.\n",
        "\n",
        "### The four problems (high level)\n",
        "\n",
        "1. **Problem 1 — N-Gram probabilities:**\n",
        "   Build unigram, bigram, and trigram models. Compute next-word probabilities in log space to avoid numerical underflow.\n",
        "\n",
        "2. **Problem 2 — Sentence probability & perplexity:**\n",
        "   Define sentence probability, normalize for sentence length, and calculate perplexity as a measure of model quality.\n",
        "\n",
        "3. **Problem 3 — Controlled generation:**\n",
        "   Implement temperature-controlled sampling to vary randomness in generated sentences. Compare low vs. high temperatures.\n",
        "\n",
        "4. **Problem 4 — Beam search:**\n",
        "   Use perplexity to guide **beam search**, keeping track of the most likely candidate sentences at each step, and compare outputs to greedy generation.\n",
        "\n",
        "By the end, you’ll have a working N-Gram generator capable of producing reasonable and a solid understanding of how early probabilistic approaches to NLP laid the foundation for modern deep learning methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZpvwwzf4tsu"
      },
      "source": [
        "### Recommended Workflow (Must Read!)\n",
        "\n",
        "One of the most important skills in machine learning is following a **disciplined workflow** when developing complex code. The basic idea is simple:\n",
        "\n",
        "1. **Start small:** Write and test your code using a tiny subset of your dataset.\n",
        "2. **Inspect your results:** Print out and examine intermediate outputs to verify that each step behaves as expected.\n",
        "3. **Iterate and tune:** Adjust hyperparameters and continue testing, gradually increasing the subset size as needed.\n",
        "4. **Scale up:** Once you are confident your code is bug-free and your hyperparameters are roughly correct, run it on the **full dataset** to obtain your final results.\n",
        "\n",
        "If you don’t have sufficient computing resources for a full run, use **as large a subset as practical** — provided you’ve begun early enough to allow for multiple iterations.\n",
        "\n",
        "\n",
        "To help you follow this workflow in this homework, I’ve included a variable `num_sentences` that controls how many sentences are used from the shuffled Brown Corpus.\n",
        "\n",
        "I recommend the following progression:\n",
        "\n",
        "* **Step 1:** Begin with `num_sentences = 10` to debug and print out intermediate data structures (such as dictionaries) to confirm that your code works as expected.\n",
        "* **Step 2:** Increase to `num_sentences = 100` to verify correctness and complete most of the homework efficiently.\n",
        "* **Step 3:** Finally, if possible, run with the full dataset (`num_sentences = 57_340`), or as large a subset as your resources allow, to answer the graded questions.\n",
        "\n",
        "\n",
        "There are 9 problems in this homework, each worth 9 points each, and you get 4 points free if you otherwise complete the homework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Inf91aCh4tsv"
      },
      "source": [
        "#### Useful Imports (add more as needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aPMn77_W4tsv"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import re\n",
        "import string\n",
        "import random\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DT4p_uAq4tsv"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Reconstruct a human-readable sentence from tokens.\n",
        "- Capitalize the first token (after removing <s>).\n",
        "- Attach any token in string.punctuation with no preceding space.\n",
        "- Attach tokens starting with an apostrophe (e.g., \"'s\", \"'ll\") with no space.\n",
        "- Capitalize standalone 'i' and 'god' wherever they appear.\n",
        "- If the last token is '.', '?', or '!', attach it without a space.\n",
        "- Ignore boundary markers <s> and </s> if present.\n",
        "Returns the sentence string and also prints it depending on flag parameter.\n",
        "'''\n",
        "\n",
        "def print_sentence(tokens, do_print=True):\n",
        "\n",
        "    if not tokens:\n",
        "        print(\"\")\n",
        "        return \"\"\n",
        "\n",
        "    # Drop boundary markers if present\n",
        "    start = 1 if tokens and tokens[0] == \"<s>\" else 0\n",
        "    end = -1 if tokens and tokens[-1] == \"</s>\" else len(tokens)\n",
        "    core = tokens[start:end]\n",
        "\n",
        "    if not core:\n",
        "        print(\"\")\n",
        "        return \"\"\n",
        "\n",
        "    # Capitalize first token\n",
        "    out = core[0].capitalize()\n",
        "\n",
        "    # Process remaining tokens with spacing rules\n",
        "    for i, t in enumerate(core[1:], start=1):\n",
        "        is_last = (i == len(core) - 1)\n",
        "\n",
        "        # Last-token punctuation rule\n",
        "        if is_last and t in {\".\", \"?\", \"!\"}:\n",
        "            out += t\n",
        "            continue\n",
        "\n",
        "        # General punctuation attaches with no space (e.g., ',', ':', ';', ')', etc.)\n",
        "        if t in string.punctuation:\n",
        "            out += t\n",
        "            continue\n",
        "\n",
        "        # Apostrophe-start tokens like \"'s\", \"'d\", \"'ll\"\n",
        "        if t.startswith(\"'\"):\n",
        "            out += t\n",
        "            continue\n",
        "\n",
        "        # Capitalize special standalone words\n",
        "        if t.lower() in {\"i\", \"god\"}:\n",
        "            out += \" \" + t.capitalize()\n",
        "            continue\n",
        "\n",
        "        # Default: add a space before normal words\n",
        "        out += \" \" + t\n",
        "\n",
        "    if do_print:\n",
        "        print(out)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtodqkBS4tsv"
      },
      "source": [
        "### Read in the list of all sentences in the Brown Corpus and process using SPaCy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Pk1ek-Tz4tsv",
        "outputId": "711876d7-ef97-4635-d919-9ac1ab69b2ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "# Must do this the first time to get the Natural Language ToolKit\n",
        "\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Bi0MdmZT4tsv",
        "outputId": "bee6b78b-312c-401c-c88a-0b0aae567b07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "/usr/local/lib/python3.12/dist-packages/spacy/pipeline/lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "import spacy\n",
        "\n",
        "nltk.download('brown')\n",
        "\n",
        "# Get all Brown corpus sentences as raw text\n",
        "# Brown is organized into categories, we flatten it into one list of sentences and shuffle\n",
        "# so we can create a shorter list for testing\n",
        "\n",
        "brown_texts = [\" \".join(sent) for sent in brown.sents()]\n",
        "\n",
        "random.shuffle(brown_texts)\n",
        "\n",
        "# Brown has 57_340 sentences, set `num_sentences` to 1000 or smaller for testing\n",
        "\n",
        "# num_sentences = 57_340\n",
        "# num_sentences = 10                           # <<<<<=====    Here is where you can change the size of the dataset\n",
        "num_sentences = 100\n",
        "\n",
        "brown_texts = brown_texts[:num_sentences]\n",
        "\n",
        "# Load spaCy English pipeline\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Process with spaCy: tokenize + sentencize\n",
        "docs = list(nlp.pipe(brown_texts, disable=[\"ner\", \"tagger\", \"parser\"]))\n",
        "\n",
        "# Each doc is one sentence; extract tokens and add beginning and ending tokens <s> ... </s>\n",
        "tokenized_sentences = [ ['<s>'] + [token.text.lower() for token in doc if not token.is_space] + ['</s>'] for doc in docs ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "299RvIuh4tsv"
      },
      "source": [
        "#### If you have trouble downloading this...\n",
        "\n",
        "\n",
        "I have uploaded a file `brown_sentences.txt` to a Google Drive folder which anyone with the link can read, just\n",
        "uncomment the code in the next cell and run it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VMoPkMde4tsv",
        "outputId": "95c0a523-609d-4880-8138-6080b4d9b025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport re, requests, random, spacy\\n\\n# Paste the shared Drive link (no need to change anything else)\\nlink = \"https://drive.google.com/file/d/1f_BkNDF0ny11Tn4D4jsOoXhgPSUCHKlf/view?usp=drive_link\"\\n\\n# --- Convert to direct download URL ---\\ndef get_direct_download_url(link):\\n    match = re.search(r\"/d/([a-zA-Z0-9_-]+)\", link) or re.search(r\"id=([a-zA-Z0-9_-]+)\", link)\\n    if not match:\\n        raise ValueError(\"Could not extract file ID from the link.\")\\n    file_id = match.group(1)\\n    return f\"https://drive.google.com/uc?export=download&id={file_id}\"\\n\\nurl = get_direct_download_url(link)\\n\\n# --- Download and prepare the text ---\\nresponse = requests.get(url)\\nlines = response.text.strip().split(\"\\n\")\\n\\nrandom.shuffle(lines)\\n\\n\\n# Etc as before\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "'''\n",
        "import re, requests, random, spacy\n",
        "\n",
        "# Paste the shared Drive link (no need to change anything else)\n",
        "link = \"https://drive.google.com/file/d/1f_BkNDF0ny11Tn4D4jsOoXhgPSUCHKlf/view?usp=drive_link\"\n",
        "\n",
        "# --- Convert to direct download URL ---\n",
        "def get_direct_download_url(link):\n",
        "    match = re.search(r\"/d/([a-zA-Z0-9_-]+)\", link) or re.search(r\"id=([a-zA-Z0-9_-]+)\", link)\n",
        "    if not match:\n",
        "        raise ValueError(\"Could not extract file ID from the link.\")\n",
        "    file_id = match.group(1)\n",
        "    return f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "\n",
        "url = get_direct_download_url(link)\n",
        "\n",
        "# --- Download and prepare the text ---\n",
        "response = requests.get(url)\n",
        "lines = response.text.strip().split(\"\\n\")\n",
        "\n",
        "random.shuffle(lines)\n",
        "\n",
        "\n",
        "# Etc as before\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DcYizV8G4tsv",
        "outputId": "7beda80b-91d8-4709-f4ba-61371ec76913",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 100\n",
            "First sentence:      He let her tell him all about the church.\n",
            "Tokenized sentence: ['<s>', 'he', 'let', 'her', 'tell', 'him', 'all', 'about', 'the', 'church', '.', '</s>']\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of sentences:\", len(tokenized_sentences))\n",
        "print(\"First sentence:      \",end='')\n",
        "print_sentence(tokenized_sentences[0])\n",
        "print(\"Tokenized sentence: \",end='')\n",
        "print(tokenized_sentences[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyOUb3D44tsw"
      },
      "source": [
        "### A Little EDA...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "avIhmcnY4tsw",
        "outputId": "9704039d-c2fd-451d-b47d-117ae90ac76d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters in the text: 11,495\n",
            "Total number of tokens:    2,187\n",
            "Number of unique tokens:   990\n",
            "Total number of sentences: 100\n",
            "Total number of words:     1,860\n",
            "Number of unique words:    950\n",
            "\n",
            "Top 10 words:\n",
            "the            : 138\n",
            "of             : 83\n",
            "and            : 57\n",
            "to             : 46\n",
            "a              : 43\n",
            "in             : 34\n",
            "that           : 21\n",
            "was            : 20\n",
            "by             : 17\n",
            "is             : 17\n",
            "\n",
            "Bottom 10 words:\n",
            "overseas       : 1\n",
            "government     : 1\n",
            "through        : 1\n",
            "organizations  : 1\n",
            "help           : 1\n",
            "foreign        : 1\n",
            "countries      : 1\n",
            "needs          : 1\n",
            "skilled        : 1\n",
            "manpower       : 1\n"
          ]
        }
      ],
      "source": [
        "# Flatten tokens (exclude spaces)\n",
        "all_tokens = [tok.text.lower() for sent in docs for tok in sent if not tok.is_space]\n",
        "\n",
        "# Define \"word\": alphabetic, or alphabetic after removing internal apostrophes\n",
        "def is_word(tok):\n",
        "    s = tok.text\n",
        "    return s.isalpha() or s.replace(\"'\", \"\").isalpha()\n",
        "\n",
        "# Extract words using the definition above\n",
        "words = [\n",
        "    tok.text.lower()\n",
        "    for sent in docs\n",
        "    for tok in sent\n",
        "    if not tok.is_space and is_word(tok)\n",
        "]\n",
        "\n",
        "# Counts\n",
        "num_chars = sum(len(s) for s in brown_texts)   # or len(text) if you started from one big text\n",
        "num_tokens = len(all_tokens)\n",
        "num_unique_tokens = len(set(all_tokens))\n",
        "num_sentences = len(docs)\n",
        "num_words = len(words)\n",
        "num_unique_words = len(set(words))\n",
        "\n",
        "print(f\"Total number of characters in the text: {num_chars:,}\")\n",
        "print(f\"Total number of tokens:    {num_tokens:,}\")\n",
        "print(f\"Number of unique tokens:   {num_unique_tokens:,}\")\n",
        "print(f\"Total number of sentences: {num_sentences:,}\")\n",
        "print(f\"Total number of words:     {num_words:,}\")\n",
        "print(f\"Number of unique words:    {num_unique_words:,}\")\n",
        "\n",
        "# Frequencies\n",
        "word_counts = Counter(words)\n",
        "most_common_words = word_counts.most_common()\n",
        "\n",
        "# Top 10\n",
        "print(\"\\nTop 10 words:\")\n",
        "for token, freq in most_common_words[:10]:\n",
        "    print(f\"{token:<15}: {freq:,}\")\n",
        "\n",
        "# Bottom 10\n",
        "print(\"\\nBottom 10 words:\")\n",
        "for token, freq in most_common_words[-10:]:\n",
        "    print(f\"{token:<15}: {freq:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO2Yls_R4tsw"
      },
      "source": [
        "### Digression: Zipf's Law\n",
        "\n",
        "Zipf's Law is an empirical regularity of natural language:  \n",
        "if you rank words by their frequency in a corpus, the frequency \\( f(r) \\) of the word at rank \\( r \\) is approximately inversely proportional to its rank:\n",
        "\n",
        "$$\n",
        "f(r) \\propto \\frac{1}{r^k}\n",
        "$$\n",
        "\n",
        "where $ r = 1, 2, 3, \\dots $ is the rank of a word (1 = most frequent), and $ k \\approx 1 $.  \n",
        "\n",
        "- The most common words (e.g., *the*, *of*, *and*) occur very often.  \n",
        "- A handful of mid-ranked words occur moderately often.  \n",
        "- The vast majority of words occur rarely.  \n",
        "\n",
        "On a **log–log plot** of frequency vs. rank, this relationship appears as a straight line with slope \\(-k\\).  \n",
        "For natural language, empirical studies show that $k \\approx 1$, which is why we plot below a reference line with slope $-1$ to compare against real corpus data.\n",
        "\n",
        "\n",
        "**Why this matters:** Because most words are rare, language models must use techniques like **smoothing, subword modeling, or embeddings** to handle sparsity and represent meaning effectively.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TRsSKxQU4tsw",
        "outputId": "8d6ef923-f5f9-44a4-9474-27f3bd52e44f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average sentence length: 21.87 tokens\n",
            "Max sentence length:     75 tokens\n"
          ]
        }
      ],
      "source": [
        "# Frequencies sorted by rank\n",
        "freqs = np.array([freq for token, freq in word_counts.most_common()])\n",
        "ranks = np.arange(1, len(freqs) + 1)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(ranks, freqs, label=\"Corpus data\")\n",
        "\n",
        "# Reference line: slope = -1 (Zipf’s law)\n",
        "# Match scale by anchoring at the first frequency\n",
        "ref_line = freqs[0] / ranks\n",
        "plt.plot(ranks, ref_line, \"--\", label=\"Reference slope = -1\")\n",
        "\n",
        "plt.xscale(\"log\")\n",
        "plt.yscale(\"log\")\n",
        "plt.title(\"Token Frequencies vs. Rank (Zipf’s Law)\")\n",
        "plt.xlabel(\"Rank of token\")\n",
        "plt.ylabel(\"Frequency of token\")\n",
        "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.6)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Compute sentence lengths from spaCy docs\n",
        "sentence_lengths = [len([tok for tok in sent if not tok.is_space]) for sent in docs]\n",
        "\n",
        "# Plot histogram\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.hist(\n",
        "    sentence_lengths,\n",
        "    bins=range(1, max(sentence_lengths) + 2),\n",
        "    color=\"skyblue\",\n",
        "    edgecolor=\"black\"\n",
        ")\n",
        "plt.title(\"Histogram of Sentence Lengths\")\n",
        "plt.xlabel(\"Sentence length (in tokens)\")\n",
        "plt.ylabel(\"Number of sentences\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Average sentence length: {sum(sentence_lengths)/len(sentence_lengths):.2f} tokens\")\n",
        "print(f\"Max sentence length:     {max(sentence_lengths)} tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS5Za_Ne4tsw"
      },
      "source": [
        "## Problem One — Build the PLM (bigrams & trigrams)\n",
        "\n",
        "For this problem, you must adapt (mostly cut-and-paste) the code from this week’s Coding Notebook to the new dataset. You are using a trigram model as well as bigrams but your professor has written code that should mostly work for any N.\n",
        "\n",
        "We provide a pre-processed dataset above, with sentences already tokenized and enclosed in the boundary tokens `<s>` and `</s>`.\n",
        "\n",
        "**Set `num_sentences=10` to start!**\n",
        "\n",
        "**ToDo:**\n",
        "\n",
        "**A.** Build N-grams for N = 2, 3\n",
        "\n",
        "- Compute all bigrams and trigrams over the tokenized sentences (boundary tokens included).\n",
        "\n",
        "**B.** Create a dictionary mapping left-contexts to next-word lists\n",
        "\n",
        "- For each N, map each context (length N−1) to a list of next tokens (allow duplicates so frequency = count).\n",
        "\n",
        "**C.** Convert to (log) probability distributions\n",
        "\n",
        "- Turn each context’s next-word list into a distribution of log-probabilities (see **Appendix Two**).\n",
        "\n",
        "**D.** Create the Probability Language Model (PLM)\n",
        "\n",
        "- Create a dictionary `get_next_word` with:\n",
        "\n",
        "    - Key: left context (tuple of 1 token for bigrams; 2 tokens for trigrams).\n",
        "    \n",
        "    - Values: nested dictionary mapping next tokens to log-probabilities `{next_token: log_prob, ...}`.\n",
        "\n",
        "- Create a **single dictionary** (since bigrams and trigrams have a left context of different lengths, and they won't get confused in the dictionary).\n",
        "\n",
        "\n",
        "**E.** Set the variable `num_sentences = 10` and do a sanity check by displaying the distribution for the bigram contexts e.g., `('<s>',)` and `('the',)` and a trigram context `('<s>','the')`. If for some reason these are not present, increase the number of sentences slightly.  \n",
        "\n",
        "**F.**  Generate 5 next words for each of the 3 examples in the previous part.\n",
        "\n",
        "**Then answer the graded questions.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5C7GsQNy4tsw",
        "outputId": "eb90a4df-dde0-468c-8b81-5090b92d16c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First sentence: ['<s>', 'he', 'let', 'her', 'tell', 'him', 'all', 'about', 'the', 'church', '.', '</s>']\n",
            "\n",
            "Bigrams:\n",
            "[('<s>', 'he'), ('he', 'let'), ('let', 'her'), ('her', 'tell'), ('tell', 'him'), ('him', 'all'), ('all', 'about'), ('about', 'the'), ('the', 'church'), ('church', '.'), ('.', '</s>')]\n",
            "\n",
            "Trigrams:\n",
            "[('<s>', 'he', 'let'), ('he', 'let', 'her'), ('let', 'her', 'tell'), ('her', 'tell', 'him'), ('tell', 'him', 'all'), ('him', 'all', 'about'), ('all', 'about', 'the'), ('about', 'the', 'church'), ('the', 'church', '.'), ('church', '.', '</s>')]\n"
          ]
        }
      ],
      "source": [
        "# Your code here (add as many cells as you need)\n",
        "# A. Build N-grams for N = 2, 3\n",
        "\n",
        "# Take a sentence and return a list of all N-grams for a given N\n",
        "def get_ngrams(sent, N):\n",
        "    return [tuple(sent[k:k+N]) for k in range(len(sent) - N + 1)]\n",
        "\n",
        "print(\"First sentence:\", tokenized_sentences[0])\n",
        "print(\"\\nBigrams:\")\n",
        "print(get_ngrams(tokenized_sentences[0], 2))\n",
        "print(\"\\nTrigrams:\")\n",
        "print(get_ngrams(tokenized_sentences[0], 3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create lists of all bigrams and trigrams\n",
        "bigrams = []\n",
        "for sent in tokenized_sentences:\n",
        "    bigrams += get_ngrams(sent, 2)\n",
        "\n",
        "trigrams = []\n",
        "for sent in tokenized_sentences:\n",
        "    trigrams += get_ngrams(sent, 3)\n",
        "\n",
        "print(f\"There are {len(bigrams)} total bigrams.\")\n",
        "print(f\"There are {len(set(bigrams))} unique bigrams.\")\n",
        "print(f\"\\nThere are {len(trigrams)} total trigrams.\")\n",
        "print(f\"There are {len(set(trigrams))} unique trigrams.\")"
      ],
      "metadata": {
        "id": "V1FYIpWW8sMQ",
        "outputId": "f20d8732-5a85-4b2c-9b0a-c5a5d31e19b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2287 total bigrams.\n",
            "There are 1953 unique bigrams.\n",
            "\n",
            "There are 2187 total trigrams.\n",
            "There are 2158 unique trigrams.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# B. Create a dictionary mapping left-contexts to next-word lists\n",
        "# Take a list of N-grams and create a next-word dictionary\n",
        "def get_next_word_dict(ngrams):\n",
        "    dict = {}\n",
        "    for ng in ngrams:\n",
        "        lcontext = ng[:-1]\n",
        "        next_word = ng[-1]\n",
        "        dict[lcontext] = dict.get(lcontext, []) + [next_word]\n",
        "    return dict\n",
        "\n",
        "# Create next-word dictionaries\n",
        "bigram_next_word_dict = get_next_word_dict(bigrams)\n",
        "trigram_next_word_dict = get_next_word_dict(trigrams)\n",
        "\n",
        "print(f\"Number of unique bigram contexts: {len(bigram_next_word_dict)}\")\n",
        "print(f\"Number of unique trigram contexts: {len(trigram_next_word_dict)}\")"
      ],
      "metadata": {
        "id": "1zTTJaQW8w38",
        "outputId": "33af0ebb-ae94-4315-f1fb-51e787460541",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique bigram contexts: 991\n",
            "Number of unique trigram contexts: 1947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C. Convert to log probability distributions\n",
        "# Turn list of tokens into a log-probability distribution dictionary\n",
        "def tokens2log_probs(ws):\n",
        "    k = len(ws)\n",
        "    return {w: math.log(f/k) for (w, f) in Counter(ws).items()}\n",
        "\n",
        "test_tokens = ['and', 'then', 'and', 'when']\n",
        "print(\"Test tokens:\", test_tokens)\n",
        "print(\"Log probabilities:\", tokens2log_probs(test_tokens))"
      ],
      "metadata": {
        "id": "JuUGkXfi89m8",
        "outputId": "c47fe86b-58c8-4352-9aee-0851d0fd7c4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test tokens: ['and', 'then', 'and', 'when']\n",
            "Log probabilities: {'and': -0.6931471805599453, 'then': -1.3862943611198906, 'when': -1.3862943611198906}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# D. Create the Probability Language Model (PLM)\n",
        "# Convert a next-word dictionary from contexts into a PLM = a dictionary from left-contexts to a probability distribution of next words\n",
        "def get_PLM(D):\n",
        "    return {lcontext: tokens2log_probs(next_words) for (lcontext, next_words) in D.items()}\n",
        "\n",
        "# Create PLMs for bigrams and trigrams\n",
        "bigram_plm = get_PLM(bigram_next_word_dict)\n",
        "trigram_plm = get_PLM(trigram_next_word_dict)\n",
        "\n",
        "# Combine into single dictionary (since contexts are different lengths, no collision)\n",
        "plm = {**bigram_plm, **trigram_plm}\n",
        "\n",
        "print(f\"Total number of contexts in combined PLM: {len(plm)}\")\n",
        "print(f\"Bigram contexts: {len(bigram_plm)}\")\n",
        "print(f\"Trigram contexts: {len(trigram_plm)}\")"
      ],
      "metadata": {
        "id": "vEvhF1P99I6Z",
        "outputId": "7d459a52-7433-4944-ef94-a5d2a21cb5b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of contexts in combined PLM: 2938\n",
            "Bigram contexts: 991\n",
            "Trigram contexts: 1947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# E. Sanity check - display distributions for specific contexts\n",
        "\n",
        "# Check if contexts exist\n",
        "if ('<s>',) in plm:\n",
        "    print(\"Bigram context ('<s>',):\")\n",
        "    print(plm[('<s>',)])\n",
        "    print()\n",
        "else:\n",
        "    print(\"Context ('<s>',) not found\")\n",
        "\n",
        "if ('the',) in plm:\n",
        "    print(\"Bigram context ('the',):\")\n",
        "    print(plm[('the',)])\n",
        "    print()\n",
        "else:\n",
        "    print(\"Context ('the',) not found\")\n",
        "\n",
        "if ('<s>', 'the') in plm:\n",
        "    print(\"Trigram context ('<s>', 'the'):\")\n",
        "    print(plm[('<s>', 'the')])\n",
        "    print()\n",
        "else:\n",
        "    print(\"Context ('<s>', 'the') not found - possibly might need more sentences!!!!!!\")"
      ],
      "metadata": {
        "id": "CEpRIBKV9XkZ",
        "outputId": "664c4368-d02f-4b95-94d7-bc18838f81d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram context ('<s>',):\n",
            "{'he': -2.8134107167600364, 'china': -4.605170185988091, 'finally': -4.605170185988091, 'a': -3.912023005428146, 'during': -4.605170185988091, 'it': -3.2188758248682006, 'just': -4.605170185988091, 'water': -4.605170185988091, 'cholesterol': -4.605170185988091, '`': -2.995732273553991, 'there': -3.506557897319982, 'acquire': -4.605170185988091, 'in': -3.506557897319982, 'theories': -4.605170185988091, 'all': -4.605170185988091, 'we': -4.605170185988091, 'to': -3.912023005428146, 'if': -4.605170185988091, 'little': -4.605170185988091, 'the': -2.3025850929940455, 'after': -3.912023005428146, 'that': -4.605170185988091, 'mrs.': -4.605170185988091, 'one': -3.912023005428146, 'two': -4.605170185988091, 'mr.': -4.605170185988091, '(': -3.912023005428146, 'nor': -4.605170185988091, 'then': -4.605170185988091, '13': -4.605170185988091, 'fromm': -4.605170185988091, 'but': -4.605170185988091, 'ambiguity': -4.605170185988091, 'as': -4.605170185988091, 'i': -3.506557897319982, 'check': -4.605170185988091, 'feelers': -4.605170185988091, 'and': -4.605170185988091, 'this': -4.605170185988091, 'she': -3.912023005428146, 'coping': -4.605170185988091, 'high': -4.605170185988091, 'opposite': -4.605170185988091, 'or': -4.605170185988091, 'soccer': -4.605170185988091, 'berman': -4.605170185988091, 'some': -4.605170185988091, 'writes': -4.605170185988091, 'vincent': -4.605170185988091, 'yet': -4.605170185988091, 'efforts': -4.605170185988091, 'calloused': -4.605170185988091, 'true': -4.605170185988091, 'americana': -4.605170185988091, 'whenever': -4.605170185988091, 'although': -4.605170185988091, 'rachel': -4.605170185988091, 'capt': -4.605170185988091, 'rousseau': -4.605170185988091, 'plank': -4.605170185988091, 'improvement': -4.605170185988091, 'enthusiastically': -4.605170185988091, 'exactly': -4.605170185988091, 'while': -4.605170185988091, 'three': -4.605170185988091, 'andrei': -4.605170185988091, 'his': -4.605170185988091}\n",
            "\n",
            "Bigram context ('the',):\n",
            "{'church': -3.828641396489095, 'people': -4.927253685157205, 'horse': -4.927253685157205, 'human': -4.927253685157205, 'council': -4.927253685157205, 'way': -4.23410650459726, 'noise': -4.927253685157205, 'summer': -4.927253685157205, 'setting': -4.927253685157205, 'saltbush': -4.927253685157205, 'bluebush': -4.927253685157205, 'hills': -4.927253685157205, 'cornerstone': -4.927253685157205, 'far': -4.927253685157205, 'office': -4.927253685157205, 'forest': -4.927253685157205, 'behavior': -4.927253685157205, 'motion': -4.927253685157205, 'elders': -4.927253685157205, 'deputies': -4.927253685157205, 'sentence': -4.927253685157205, 'pathet': -4.927253685157205, 'denomination': -4.927253685157205, 'rev.': -4.927253685157205, 'vision': -4.927253685157205, 'next': -4.927253685157205, 'final': -4.927253685157205, 'ring': -4.927253685157205, 'synthetic': -4.927253685157205, 'president': -4.927253685157205, 'necessity': -4.927253685157205, 'ferry': -4.927253685157205, 'genuinely': -4.927253685157205, 'degree': -4.927253685157205, 'suitcase': -4.927253685157205, 'various': -4.927253685157205, 'missile': -4.23410650459726, 'target': -4.927253685157205, 'flight': -4.927253685157205, 'opportunity': -4.927253685157205, 'cat': -4.927253685157205, 'bag': -4.927253685157205, 'sphere': -4.927253685157205, 'concepts': -4.927253685157205, 'bureaucratization': -4.927253685157205, 'corporation': -4.927253685157205, 'separation': -4.927253685157205, 'broad': -4.927253685157205, 'point': -4.927253685157205, 'eternal': -4.927253685157205, 'world': -4.23410650459726, 'pronoun': -4.927253685157205, 'favorite': -4.927253685157205, 'kitchen': -4.23410650459726, 'quality': -4.927253685157205, 'water': -4.927253685157205, 'pictures': -4.927253685157205, 'speed': -4.927253685157205, 'united': -3.828641396489095, 'velvet': -4.927253685157205, 'closet': -4.927253685157205, 'city': -4.927253685157205, 'potowomut': -4.927253685157205, 'outcome': -4.927253685157205, 'difference': -4.927253685157205, 'number': -4.927253685157205, 'cafeteria': -4.927253685157205, 'usis': -4.927253685157205, 'university': -4.927253685157205, 'belgians': -4.927253685157205, 'economic': -4.927253685157205, 'congo': -4.927253685157205, 'ruddiness': -4.927253685157205, 'heat': -4.927253685157205, 'stubble': -4.927253685157205, 'hill': -4.927253685157205, 'farm': -4.927253685157205, 'most': -4.23410650459726, 'left': -4.927253685157205, 'person': -4.927253685157205, 'uncas': -4.927253685157205, 'order': -4.927253685157205, 'republic': -4.927253685157205, 'inconsequential': -4.927253685157205, 'terminal': -4.927253685157205, 'community': -4.927253685157205, 'philippines': -4.927253685157205, 'smoothness': -4.927253685157205, 'opposite': -4.927253685157205, 'effect': -4.927253685157205, 'vehicle': -4.927253685157205, 'secretary': -4.927253685157205, 'treasury': -4.927253685157205, 'comptroller': -4.927253685157205, 'case': -4.927253685157205, 'social': -4.927253685157205, 'teacher': -4.927253685157205, 'latter': -4.927253685157205, 'area': -4.927253685157205, 'installation': -4.927253685157205, 'buildings': -4.927253685157205, 'sorrentine': -4.927253685157205, '`': -3.828641396489095, 'sides': -4.927253685157205, 'stem': -4.927253685157205, 'transom': -4.927253685157205, 'original': -4.927253685157205, 'early': -4.927253685157205, 'women': -4.927253685157205, 'grateful': -4.927253685157205, 'army': -4.927253685157205, 'new': -4.23410650459726, 'crown': -4.927253685157205, 'concept': -4.927253685157205, 'communion': -4.927253685157205, 'criminal': -4.927253685157205, 'electoral': -4.927253685157205, 'newly': -4.927253685157205, 'bloodstream': -4.927253685157205, 'former': -4.927253685157205, 'hero': -4.927253685157205, 'other': -4.927253685157205, 'villain': -4.927253685157205, 'congress': -4.927253685157205, 'establishment': -4.927253685157205, 'u.s.': -4.927253685157205}\n",
            "\n",
            "Trigram context ('<s>', 'the'):\n",
            "{'president': -2.3025850929940455, 'genuinely': -2.3025850929940455, 'church': -2.3025850929940455, 'favorite': -2.3025850929940455, 'velvet': -2.3025850929940455, 'belgians': -2.3025850929940455, 'most': -2.3025850929940455, 'latter': -2.3025850929940455, 'grateful': -2.3025850929940455, '`': -2.3025850929940455}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# F. Generate 5 next words for each of the 3 contexts\n",
        "# Get next word by sampling from the probability distribution.\n",
        "# Uses log probabilities, so convert back to regular probabilities for sampling\n",
        "def get_next_word(lcontext, plm):\n",
        "    next_word_dist = plm[lcontext]\n",
        "\n",
        "    # Convert log probs back to regular probs\n",
        "    tokens = list(next_word_dist.keys())\n",
        "    log_probs = list(next_word_dist.values())\n",
        "\n",
        "    # Convert to regular probabilities\n",
        "    max_log_prob = max(log_probs)\n",
        "    probs = [math.exp(lp - max_log_prob) for lp in log_probs]\n",
        "\n",
        "    # Normalize\n",
        "    total = sum(probs)\n",
        "    probs = [p/total for p in probs]\n",
        "\n",
        "    return random.choices(tokens, weights=probs)[0]\n",
        "\n",
        "# Generate 5 next words for each context\n",
        "contexts_to_test = [('<s>',), ('the',), ('<s>', 'the')]\n",
        "\n",
        "for context in contexts_to_test:\n",
        "    if context in plm:\n",
        "        print(f\"\\nContext {context}:\")\n",
        "        next_words = [get_next_word(context, plm) for _ in range(5)]\n",
        "        print(f\"5 generated next words: {next_words}\")\n",
        "    else:\n",
        "        print(f\"\\nContext {context} not found in PLM\")"
      ],
      "metadata": {
        "id": "HYc16XaX9vQq",
        "outputId": "fbf7035b-7561-4364-a1f3-5045ba765000",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context ('<s>',):\n",
            "5 generated next words: ['the', 'two', 'china', 'while', 'one']\n",
            "\n",
            "Context ('the',):\n",
            "5 generated next words: ['degree', 'missile', 'rev.', 'early', 'united']\n",
            "\n",
            "Context ('<s>', 'the'):\n",
            "5 generated next words: ['genuinely', 'velvet', 'belgians', 'velvet', 'president']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5zbufuq4tsw"
      },
      "source": [
        "### Graded Question:\n",
        "\n",
        "In the next cell, set `a1` to the list of 5 next words for the trigram context `('<s>','the')` (unlikely, but you may have to adjust `num_sentences` as indicated)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "X4Sl45T64tsw"
      },
      "outputs": [],
      "source": [
        "# Your answer here\n",
        "\n",
        "a1 = [get_next_word(('<s>', 'the'), plm) for _ in range(5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Q5D13EkW4tsw",
        "outputId": "0a2fe551-82ff-433d-d958-2f5566dc5c7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a1 = ['latter', 'church', 'favorite', 'grateful', 'president']\n"
          ]
        }
      ],
      "source": [
        "# Graded Answer\n",
        "# DO NOT change this cell in any way and do not make any other assignments to variable a1 in this problem\n",
        "\n",
        "print(f'a1 = {a1}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxMnCiTt4tsw"
      },
      "source": [
        "## Problem Two: Generating Sentences with Backoff and Temperature\n",
        "\n",
        "\n",
        "The algorithm for generating sentences from a N-Gram PLM is simple: look at the last $N-1$ tokens of the sentence and use the probability distribution of next words to select the continuation word; stop when you generate `'</s>'`.\n",
        "\n",
        "\n",
        "For **bigrams**, this works well: Every token in the text is followed by another token (because `</s>` ends every sentence).\n",
        "\n",
        "However there are two problems when using N-grams for $N>2$:\n",
        "\n",
        "**1. Cold Start (not enough left-context):**  You don't have enough left context in the beginning, so you start with what you have until you have enough left context.   For example, with trigrams:\n",
        "\n",
        "                                          Find next word using:\n",
        "        Step 1:    <s> ?                      bigrams\n",
        "         context:  ---\n",
        "        Step 2:    <s> One ?                  trigrams\n",
        "         context:  ------\n",
        "        Step 3:    <s> One ish ?             continue on with trigrams\n",
        "         context:      ---------\n",
        "\n",
        "\n",
        "**2. Sparsity (not enough N-grams):** For bigrams we always have a continuation for the left context (1 token). However, it is possible for $N>2$ that there is no N-gram which gives you a choice of next words, for example, suppose your sentence so far is\n",
        "\n",
        "            \"One fish dish ...\"\n",
        "\n",
        "and there is no trigram in the form `(\"fish\", \"dish\", ...)`. In this case we use the **backoff** strategy: if there is no trigram left-context `(\"fish\", \"dish\")`,\n",
        "cut out one token and use the (safe) bigram strategy with left context `(\"dish\",)`.  In general, for any $N$,\n",
        "if $N$ does not provide a next word, try $N-1$, $N-2$ etc. until one is found (in the worse case,\n",
        "for $N=1$, you'll just select a likely word without any left-context, but note that with boundary tokens, you'll\n",
        "always have a bigram).\n",
        "\n",
        "\n",
        "**ToDo:**\n",
        "\n",
        "- Adapt the code for generating sentences from the Coding Video to perform the backoff strategy just described, and using your code from Problem One.\n",
        "- Make sure you convert the log probabilities **back into non-log probabilities before you use them as weights in in `np.choice(..., p=weights)`**.\n",
        "- Perform 3 experiments with temperature set at 0.2, 1.0, and 5.0 **with the full dataset if possible**:\n",
        "    - Generate 10 sentences for each temperature, print them out using `print_sentence` and observe whatever differences you can.\n",
        "- Answer the graded questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "25ZWCVde4tsw",
        "outputId": "78e6ed06-974b-4f76-8e8b-34e8958ff12c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing with context ('<s>', 'the'):\n",
            "  Next word 1: velvet\n",
            "  Next word 2: latter\n",
            "  Next word 3: belgians\n",
            "  Next word 4: president\n",
            "  Next word 5: belgians\n"
          ]
        }
      ],
      "source": [
        "# Your code here (add as many cells as you need)\n",
        "# Function to get next word with backoff strategy and temperature\n",
        "\n",
        "# Get next word using backoff strategy and temperature.\n",
        "# - lcontext: tuple of tokens (left context)\n",
        "# - plm: probability language model dictionary\n",
        "# - temp: temperature for sampling\n",
        "\n",
        "# If lcontext not found, back off to shorter context.\n",
        "\n",
        "def get_next_word_backoff(lcontext, plm, temp=1.0):\n",
        "    # Try current context\n",
        "    current_context = lcontext\n",
        "\n",
        "    # Back off until we find a context that exists in the PLM\n",
        "    while current_context not in plm and len(current_context) > 0:\n",
        "        current_context = current_context[1:]  # Remove leftmost token\n",
        "\n",
        "    # If still not found, fall back to empty context (shouldn't happen with proper PLM)\n",
        "    if current_context not in plm:\n",
        "        # This shouldn't happen, but as a safety, pick a random context\n",
        "        current_context = random.choice(list(plm.keys()))\n",
        "\n",
        "    # Get the log probability distribution for next words\n",
        "    next_word_log_dist = plm[current_context]\n",
        "\n",
        "    # Convert to lists for processing\n",
        "    tokens = list(next_word_log_dist.keys())\n",
        "    log_probs = list(next_word_log_dist.values())\n",
        "\n",
        "    # Convert log probs to regular probs with numerical stability\n",
        "    max_log_prob = max(log_probs)\n",
        "    probs = [math.exp(lp - max_log_prob) for lp in log_probs]\n",
        "\n",
        "    # Apply temperature\n",
        "    if temp != 1.0:\n",
        "        probs = np.array(probs, dtype=np.float64)\n",
        "        probs = np.clip(probs, 1e-12, 1.0)  # Avoid log(0)\n",
        "        scaled = np.exp(np.log(probs) / temp)\n",
        "        probs = (scaled / np.sum(scaled)).tolist()\n",
        "    else:\n",
        "        # Just normalize without temperature\n",
        "        total = sum(probs)\n",
        "        probs = [p/total for p in probs]\n",
        "\n",
        "    # Sample next word\n",
        "    return random.choices(tokens, weights=probs)[0]\n",
        "\n",
        "# Test the function\n",
        "test_context = ('<s>', 'the')\n",
        "print(f\"Testing with context {test_context}:\")\n",
        "for i in range(5):\n",
        "    next_word = get_next_word_backoff(test_context, plm, temp=1.0)\n",
        "    print(f\"  Next word {i+1}: {next_word}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate a complete sentence with backoff\n",
        "\n",
        "# Generate a sentence using N-gram model with backoff and temperature.\n",
        "# - plm: probability language model dictionary\n",
        "# - N: maximum N-gram order\n",
        "# - temp: temperature for sampling\n",
        "# - max_len: maximum sentence length to prevent infinite loops\n",
        "def get_sentence_backoff(plm, N=3, temp=1.0, max_len=100):\n",
        "    sentence = ['<s>']\n",
        "\n",
        "    while sentence[-1] != '</s>' and len(sentence) < max_len:\n",
        "        # Determine left context size based on current sentence length\n",
        "        # Start with smaller context if we don't have enough tokens yet\n",
        "        context_size = min(N - 1, len(sentence))\n",
        "        lcontext = tuple(sentence[-context_size:]) if context_size > 0 else tuple()\n",
        "\n",
        "        # Get next word with backoff\n",
        "        next_word = get_next_word_backoff(lcontext, plm, temp=temp)\n",
        "        sentence.append(next_word)\n",
        "\n",
        "    return sentence\n",
        "\n",
        "# Test sentence generation\n",
        "print(\"Testing sentence generation with trigram model (N=3):\\n\")\n",
        "for i in range(3):\n",
        "    sent = get_sentence_backoff(plm, N=3, temp=1.0)\n",
        "    print(f\"Sentence {i+1}:\")\n",
        "    print_sentence(sent)\n",
        "    print()"
      ],
      "metadata": {
        "id": "NG2PU1Sbl6FB",
        "outputId": "db63edf1-8123-4238-f6e3-236c4496dcb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing sentence generation with trigram model (N=3):\n",
            "\n",
            "Sentence 1:\n",
            "To step up the denomination's program, the rev. mr. brandt suggested the vision of 8,000 new assemblies of God churches in the way to dress than college students.\n",
            "\n",
            "Sentence 2:\n",
            "One bronchial arteriolar- pulmonary arteriolar anastomosis was noted at the far end and in another by the united states, as pentagon mutterers labeled it, apparently was a post of honor, held inviolate for him;;\n",
            "\n",
            "Sentence 3:\n",
            "`` hold- back'', watching to see to the congress the establishment of a married couple may reflect an abiding belief that the communion between husband and wife is such that their actions are not always to be similar in potency, composition and physical properties.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate a complete sentence with backoff\n",
        "# Generate a sentence using N-gram model with backoff and temperature.\n",
        "#     - plm: probability language model dictionary\n",
        "#     - N: maximum N-gram order (e.g., 3 for trigrams)\n",
        "#     - temp: temperature for sampling\n",
        "#     - max_len: maximum sentence length to prevent infinite loops\n",
        "def get_sentence_backoff(plm, N=3, temp=1.0, max_len=100):\n",
        "    sentence = ['<s>']\n",
        "\n",
        "    while sentence[-1] != '</s>' and len(sentence) < max_len:\n",
        "        # Determine left context size based on current sentence length\n",
        "        # Start with smaller context if we don't have enough tokens yet\n",
        "        context_size = min(N - 1, len(sentence))\n",
        "        lcontext = tuple(sentence[-context_size:]) if context_size > 0 else tuple()\n",
        "\n",
        "        # Get next word with backoff\n",
        "        next_word = get_next_word_backoff(lcontext, plm, temp=temp)\n",
        "        sentence.append(next_word)\n",
        "\n",
        "    return sentence\n",
        "\n",
        "# Test sentence generation\n",
        "print(\"Testing sentence generation with trigram model (N=3):\\n\")\n",
        "for i in range(3):\n",
        "    sent = get_sentence_backoff(plm, N=3, temp=1.0)\n",
        "    print(f\"Sentence {i+1}:\")\n",
        "    print_sentence(sent)\n",
        "    print()"
      ],
      "metadata": {
        "id": "BCg0MiFx-NXF",
        "outputId": "39998857-7854-4057-a39a-b275ef9dca8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing sentence generation with trigram model (N=3):\n",
            "\n",
            "Sentence 1:\n",
            "He was not a new experience to ekstrohm.\n",
            "\n",
            "Sentence 2:\n",
            "Acquire secret processes, technical data, inventions, patent applications, patents, licenses, land and interests in land( including water rights), plants and facilities, and cotton and palm oil.\n",
            "\n",
            "Sentence 3:\n",
            "Finally, it is, they are in having the world.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 1: Temperature = 0.2 (Low - more focused/deterministic)\n",
        "\n",
        "print(\"EXPERIMENT 1: Temperature = 0.2 (Low - focused, deterministic)\")\n",
        "print(\"-\" * 70)\n",
        "print()\n",
        "\n",
        "temperature = 0.2\n",
        "sentences_temp_02 = []\n",
        "\n",
        "for i in range(10):\n",
        "    sent = get_sentence_backoff(plm, N=3, temp=temperature)\n",
        "    sentences_temp_02.append(sent)\n",
        "    print(f\"Sentence {i+1}:\")\n",
        "    print_sentence(sent)\n",
        "    print()"
      ],
      "metadata": {
        "id": "N02nDGZ7B2rW",
        "outputId": "a6d72e48-77ce-4a13-ecd7-ba5a7de435de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXPERIMENT 1: Temperature = 0.2 (Low - focused, deterministic)\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Sentence 1:\n",
            "The grateful way she looked at morgan made him ashamed of himself.\n",
            "\n",
            "Sentence 2:\n",
            "The belgians were interested primarily in the economic development of children, the hills roll softly.\n",
            "\n",
            "Sentence 3:\n",
            "The church today stands in the cafeteria, the new country the electoral process is considered as a night club monologist, proved himself very much at home in musical comedy.\n",
            "\n",
            "Sentence 4:\n",
            "The most prominent magazine illustrators in america;;\n",
            "\n",
            "Sentence 5:\n",
            "`` we must keep the bloodstream of new jersey in the early 1920s following adoption of the way of unity.\n",
            "\n",
            "Sentence 6:\n",
            "The favorite excuse of those who have now recanted their approval of communism is that they did not know how things would develop.\n",
            "\n",
            "Sentence 7:\n",
            "The grateful way she looked at morgan made him ashamed of himself.\n",
            "\n",
            "Sentence 8:\n",
            "The belgians were interested primarily in the closet.\n",
            "\n",
            "Sentence 9:\n",
            "The most active preparations obtained by these two groups of investigators appear to be similar in potency, composition and physical properties.\n",
            "\n",
            "Sentence 10:\n",
            "The belgians were interested primarily in the closet.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2: Temperature = 1.0 (Medium - balanced)\n",
        "\n",
        "print(\"EXPERIMENT 2: Temperature = 1.0 (Balanced)\")\n",
        "print(\"-\" * 70)\n",
        "print()\n",
        "\n",
        "temperature = 1.0\n",
        "sentences_temp_10 = []\n",
        "\n",
        "for i in range(10):\n",
        "    sent = get_sentence_backoff(plm, N=3, temp=temperature)\n",
        "    sentences_temp_10.append(sent)\n",
        "    print(f\"Sentence {i+1}:\")\n",
        "    print_sentence(sent)\n",
        "    print()"
      ],
      "metadata": {
        "id": "ncx8vp5EB9ta",
        "outputId": "10a567b3-f105-40ae-db58-b8c899da3426",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXPERIMENT 2: Temperature = 1.0 (Balanced)\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Sentence 1:\n",
            "Andrei remembered a bathyran meeting long ago.\n",
            "\n",
            "Sentence 2:\n",
            "Enthusiastically, americans have swept subliterary and bogus materials like paul bunyan tales, abe lincoln anecdotes and labor union songs up as true products of our american oral tradition.\n",
            "\n",
            "Sentence 3:\n",
            "Or who undertook to set records for remaining erect on a dance floor, with or without a partner;;\n",
            "\n",
            "Sentence 4:\n",
            "One must first detect a fleeting mobile or moving target, compute ballistics for the social development of children, the teacher can find a great deal of information concerning types of social behavior normally displayed by children at various age levels.\n",
            "\n",
            "Sentence 5:\n",
            "Water rationing will be to remove as far as possible whatever in the philippines have demonstrated that transitional societies can work toward balanced national development.\n",
            "\n",
            "Sentence 6:\n",
            "We were told that to the kitchen.\n",
            "\n",
            "Sentence 7:\n",
            "The velvet smoking jackets, pearl- gray, wine, and when the pronoun it carries a twofold reference.\n",
            "\n",
            "Sentence 8:\n",
            "There was no close examination of his clothes for bloodstains, and said,`` hold- back'', herr schaffner said.\n",
            "\n",
            "Sentence 9:\n",
            "`` but you ca n't ride into the ring because it is worthy of destruction, select the missile for firing.\n",
            "\n",
            "Sentence 10:\n",
            "Finally, it is worthwhile to recall that fromm's analysis of alienation in the new country the electoral process is considered as a night club monologist, proved himself very much at home in musical comedy.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 3: Temperature = 5.0 (High - more random/creative)\n",
        "\n",
        "print(\"EXPERIMENT 3: Temperature = 5.0 (High - random, creative)\")\n",
        "print(\"-\" * 70)\n",
        "print()\n",
        "\n",
        "temperature = 5.0\n",
        "sentences_temp_50 = []\n",
        "\n",
        "for i in range(10):\n",
        "    sent = get_sentence_backoff(plm, N=3, temp=temperature)\n",
        "    sentences_temp_50.append(sent)\n",
        "    print(f\"Sentence {i+1}:\")\n",
        "    print_sentence(sent)\n",
        "    print()"
      ],
      "metadata": {
        "id": "lFbazmprB85S",
        "outputId": "a6e2a98f-7104-42e3-d492-4bae5c491002",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXPERIMENT 3: Temperature = 5.0 (High - random, creative)\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Sentence 1:\n",
            "If you walk into the ferry.\n",
            "\n",
            "Sentence 2:\n",
            "Calloused fingers, caressed only by the united states, its officers, agents, or the comptroller general of the human than any other person against the target, compute ballistics for the social development of children, the stem and the bluebush, has been designated a cavaliere of the sorrentine peninsula, had swayed excitedly beneath puckered chins where tiny black hairs sprouted, never to be tweezed away.\n",
            "\n",
            "Sentence 3:\n",
            "He saw the suitcase, which is rich in copper, tin, cobalt, manganese, zinc, and cotton and palm oil.\n",
            "\n",
            "Sentence 4:\n",
            "Mr. mccormack.\n",
            "\n",
            "Sentence 5:\n",
            "Andrei remembered a bathyran meeting long ago.\n",
            "\n",
            "Sentence 6:\n",
            "Finally, it shall be an absolute bar to recovery by any other presently known species.\n",
            "\n",
            "Sentence 7:\n",
            "Acquire secret processes, technical data, inventions, patent applications, patents, licenses, land and interests in land( including water rights), plants and facilities, and uranium, and said,`` but you ca n't ride into the ring because it is softened by the office.\n",
            "\n",
            "Sentence 8:\n",
            "Vincent sorrentino, founder and board chairman of the women's suffrage amendment.\n",
            "\n",
            "Sentence 9:\n",
            "Finally, it is worthwhile to recall that fromm's analysis of alienation in the economic development of children, the kitchen.\n",
            "\n",
            "Sentence 10:\n",
            "Vincent sorrentino, founder and board chairman of the`` you really in a container at the far end and in another by the various churches.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect all sentences from all experiments\n",
        "all_sentences = sentences_temp_02 + sentences_temp_10 + sentences_temp_50\n",
        "\n",
        "# Print all sentences with indices for selection\n",
        "print(\"All generated sentences:\")\n",
        "print()\n",
        "for idx, sent in enumerate(all_sentences):\n",
        "    print(f\"[{idx}] \", end=\"\")\n",
        "    print_sentence(sent)\n",
        "    print()\n",
        "\n",
        "best_sentence_index = 0\n",
        "\n",
        "a2a = print_sentence(all_sentences[best_sentence_index], do_print=False)\n",
        "print(f\"\\nSelected most realistic sentence (index {best_sentence_index}):\")\n",
        "print(f\"a2a = '{a2a}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22xur_BICiQ2",
        "outputId": "337d9725-692e-4ae7-fa76-7c570d80e7b8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All generated sentences:\n",
            "\n",
            "[0] The grateful way she looked at morgan made him ashamed of himself.\n",
            "\n",
            "[1] The belgians were interested primarily in the economic development of children, the hills roll softly.\n",
            "\n",
            "[2] The church today stands in the cafeteria, the new country the electoral process is considered as a night club monologist, proved himself very much at home in musical comedy.\n",
            "\n",
            "[3] The most prominent magazine illustrators in america;;\n",
            "\n",
            "[4] `` we must keep the bloodstream of new jersey in the early 1920s following adoption of the way of unity.\n",
            "\n",
            "[5] The favorite excuse of those who have now recanted their approval of communism is that they did not know how things would develop.\n",
            "\n",
            "[6] The grateful way she looked at morgan made him ashamed of himself.\n",
            "\n",
            "[7] The belgians were interested primarily in the closet.\n",
            "\n",
            "[8] The most active preparations obtained by these two groups of investigators appear to be similar in potency, composition and physical properties.\n",
            "\n",
            "[9] The belgians were interested primarily in the closet.\n",
            "\n",
            "[10] Andrei remembered a bathyran meeting long ago.\n",
            "\n",
            "[11] Enthusiastically, americans have swept subliterary and bogus materials like paul bunyan tales, abe lincoln anecdotes and labor union songs up as true products of our american oral tradition.\n",
            "\n",
            "[12] Or who undertook to set records for remaining erect on a dance floor, with or without a partner;;\n",
            "\n",
            "[13] One must first detect a fleeting mobile or moving target, compute ballistics for the social development of children, the teacher can find a great deal of information concerning types of social behavior normally displayed by children at various age levels.\n",
            "\n",
            "[14] Water rationing will be to remove as far as possible whatever in the philippines have demonstrated that transitional societies can work toward balanced national development.\n",
            "\n",
            "[15] We were told that to the kitchen.\n",
            "\n",
            "[16] The velvet smoking jackets, pearl- gray, wine, and when the pronoun it carries a twofold reference.\n",
            "\n",
            "[17] There was no close examination of his clothes for bloodstains, and said,`` hold- back'', herr schaffner said.\n",
            "\n",
            "[18] `` but you ca n't ride into the ring because it is worthy of destruction, select the missile for firing.\n",
            "\n",
            "[19] Finally, it is worthwhile to recall that fromm's analysis of alienation in the new country the electoral process is considered as a night club monologist, proved himself very much at home in musical comedy.\n",
            "\n",
            "[20] If you walk into the ferry.\n",
            "\n",
            "[21] Calloused fingers, caressed only by the united states, its officers, agents, or the comptroller general of the human than any other person against the target, compute ballistics for the social development of children, the stem and the bluebush, has been designated a cavaliere of the sorrentine peninsula, had swayed excitedly beneath puckered chins where tiny black hairs sprouted, never to be tweezed away.\n",
            "\n",
            "[22] He saw the suitcase, which is rich in copper, tin, cobalt, manganese, zinc, and cotton and palm oil.\n",
            "\n",
            "[23] Mr. mccormack.\n",
            "\n",
            "[24] Andrei remembered a bathyran meeting long ago.\n",
            "\n",
            "[25] Finally, it shall be an absolute bar to recovery by any other presently known species.\n",
            "\n",
            "[26] Acquire secret processes, technical data, inventions, patent applications, patents, licenses, land and interests in land( including water rights), plants and facilities, and uranium, and said,`` but you ca n't ride into the ring because it is softened by the office.\n",
            "\n",
            "[27] Vincent sorrentino, founder and board chairman of the women's suffrage amendment.\n",
            "\n",
            "[28] Finally, it is worthwhile to recall that fromm's analysis of alienation in the economic development of children, the kitchen.\n",
            "\n",
            "[29] Vincent sorrentino, founder and board chairman of the`` you really in a container at the far end and in another by the various churches.\n",
            "\n",
            "\n",
            "Selected most realistic sentence (index 0):\n",
            "a2a = 'The grateful way she looked at morgan made him ashamed of himself.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjndEdEO4tsw"
      },
      "source": [
        "### Graded Questions:\n",
        "\n",
        "#### Part 2A: In the next cell, set `a2a` to the *most realistic sentence* generated (your call!). Use `print_sentence(..., do_print=False)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "tnIsZeHV4tsw"
      },
      "outputs": [],
      "source": [
        "# Your answer here\n",
        "a2a = print_sentence(all_sentences[best_sentence_index], do_print=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "V6TG_gO94tsw",
        "outputId": "09b45a4d-e382-4a21-cb05-83ed0fb04050",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a2a = The grateful way she looked at morgan made him ashamed of himself.\n"
          ]
        }
      ],
      "source": [
        "# Graded Answer\n",
        "# DO NOT change this cell in any way and do not make any other assignments to variable a2a in this problem\n",
        "\n",
        "print(f'a2a = {a2a}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7fsr3DO4tsw"
      },
      "source": [
        "#### Part 2B:  Describe in a few sentences what you observed with the different temperature settings (and try more if you wish!). Which seemed to produce the most realistic sentences?\n",
        "\n",
        "Your answer here:\n",
        "\n",
        "\n",
        "The Temperature 0.2 (low) model produced more repetitive and deterministic outputs. Several sentences were duplicated (for example: \"The grateful way she looked at morgan made him ashamed of himself\" and \"The belgians were interested primarily in the closet\" appeared multiple times). The sentences started coherent but often had more predictable and less diverse word choices.\n",
        "The Temperature 1.0 (balanced) setting produced the most realistic and varied sentences. The outputs were grammatically correct, semantically coherent, and showed good diversity without being too random. Sentences like \"Andrei remembered a bathyran meeting long ago\" and \"The grateful way she looked at morgan made him ashamed of himself\" are completely natural. The only critique is that I am not sure what a \"bathyran meeting\" is and the incorrect capitalization of \"morgan.\"\n",
        "The Temperature 5.0 (high) model generated more creative but often incoherent sentences. These outputs were longer, more chaotic, and contained unusual word combinations and run-on structures. While diverse, they often lacked logical flow and semantic coherence (for example: the very long sentence about \"calloused fingers\" and \"puckered chins\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHybhEyL4tsw"
      },
      "source": [
        "## Problem Three:  Measuring the Quality of Sentences:  Average Log Probability and Perplexity\n",
        "\n",
        "The probabilities involved when we start to calculate the probability of longer token sequences are extremely small, and underflow is common\n",
        "for a large corpus. Therefore we calculate all probabilities in **log space** (see **Appendix Two** for an explanation).\n",
        "\n",
        "Basically, the quality metric for generated sentences is likelihood: If a sentence is more probable, it is better.\n",
        "However, this metric is biased towards short sentences, since we multiply the probabilities of each word,\n",
        "and long sentences end up being very unlikely. But natural language does not behave this way!\n",
        "\n",
        "Therefore, we will remove the length from the calculation using the following measures:\n",
        "\n",
        "**Average of Log Probabilities (ALP)** is a length-agnostic measure of sentence probability. For trigrams:\n",
        "\n",
        "Let the tokenized sentence be $[t_1,\\ldots,t_n]$ with $t_1$ = `<s>` and $t_n$ = `</s>`.\n",
        "\n",
        "\n",
        "$$\n",
        "\\text{ALP}([t_1, t_2, \\dots, t_n])\n",
        "\\ =\\ \\frac{\\log P(t_2 \\mid t_1) + \\log P(t_3 \\mid t_1, t_2) + \\dots + \\log P(t_n \\mid t_{n-2}, t_{n-1})}{n-1}\n",
        "$$\n",
        "\n",
        "**Notes:**\n",
        "- We don't include the first token because it is always present and hence not predicted; think of\n",
        "it as a prompt which gets the sentence going!\n",
        "- To account for backoff, simply use the log probability of the bigram in those cases instead of the trigram.\n",
        "- ALP is in $(-\\infty \\ldots 0.0]$ and larger is better.  It grows more negative as the model performs worse.\n",
        "\n",
        "\n",
        "**Perplexity** is the most common metric in NLP: it rescales the ALP into a more intuitive, positive scale:\n",
        "\n",
        "> Perplexity = np.exp( - ALP ).     \n",
        "\n",
        "Perplexities are $\\ge 1.0$ and smaller is better.   A larger perplexity means the model is “more perplexed,” i.e., on average it is choosing among more equally likely alternatives.\n",
        "\n",
        "Because the exponential is monotonic, minimizing perplexity is exactly the same as maximizing average log probability—so either metric may be used for ranking models, but perplexity is more commonly used by the NLP community.\n",
        "\n",
        "### Before You Start\n",
        "\n",
        "You can compute ALP during generation by carrying **state** along with the partial sentence.\n",
        "Instead of storing:\n",
        "\n",
        "> tokens_so_far = [ `<s>`, $t_2$, $t_3$, … ]\n",
        "\n",
        "store a **pair**:\n",
        "\n",
        "> ( tokens_so_far, sum_log_probs)\n",
        "\n",
        "where\n",
        "\n",
        "* **sum_log_probs** = $( \\log P(t_2\\mid t_1) + \\log P(t_3\\mid t_1,t_2) + \\cdots )$\n",
        "\n",
        "In the case that backoff was used to generate some $t_k$, you just use $\\log P(t_{k}\\mid t_{k-1})$\n",
        "\n",
        "Then your loop is:\n",
        "\n",
        "1. Start with tokens = `['<s>']` and `sum_log_probs = 0.0`.\n",
        "2. Get the left context (trigram preferred; back off to bigram if needed).\n",
        "3. **Sample** the next token using temperature, but **score** with the model’s **true** log-prob for that token (un-tempered): update `sum_log_probs += log P(next|context)`.\n",
        "4. Append the token; if it is `</s>`, stop, else repeat froms step 2.\n",
        "5. Calculate the perplexity of the completed sentence:\n",
        "- Divide the running sum of log probabilities by `len(tokens)-1` to get the final ALP.\n",
        "- Calculate `PP = np.exp(-ALP)` and return the pair `( completed-list-of-tokens, PP)` as the generated sentence.\n",
        "\n",
        "\n",
        "\n",
        "### To Do\n",
        "\n",
        "* Modify your `get_next_word` and sentence generator method to maintain `(tokens, sum_log)` as above and return `(tokens, Perplexity)`.\n",
        "- Perform 3 experiments with temperature set at 0.2, 1.0, and 5.0 **with the full dataset if possible**:\n",
        "    - Generate 10 sentences for each temperature, print them out using `print_sentence` and observe whatever differences you can, comparing them with the perplexity.\n",
        "* Answer the graded questions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "IegCJbtv4tsx",
        "outputId": "76905019-7c06-44ca-d518-14e367d7278b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing with context ('<s>', 'the'):\n",
            "\n",
            "  Word: favorite        | Log P: -2.3026 | Context used: ('<s>', 'the')\n",
            "  Word: velvet          | Log P: -2.3026 | Context used: ('<s>', 'the')\n",
            "  Word: president       | Log P: -2.3026 | Context used: ('<s>', 'the')\n",
            "  Word: velvet          | Log P: -2.3026 | Context used: ('<s>', 'the')\n",
            "  Word: belgians        | Log P: -2.3026 | Context used: ('<s>', 'the')\n"
          ]
        }
      ],
      "source": [
        "# Your code here: add as many cells as you wish\n",
        "# Modified function to get next word and return its log probability\n",
        "# Get next word using backoff strategy and temperature.\n",
        "# Returns: (next_word, log_prob, context_used)\n",
        "# - next_word: the sampled token\n",
        "# - log_prob: the TRUE log probability from the model (not temperature-adjusted)\n",
        "# - context_used: the actual context used (after backoff if needed)\n",
        "\n",
        "def get_next_word_with_log_prob(lcontext, plm, temp=1.0):\n",
        "    # Try current context, back off if needed\n",
        "    current_context = lcontext\n",
        "\n",
        "    while current_context not in plm and len(current_context) > 0:\n",
        "        current_context = current_context[1:]  # Remove leftmost token\n",
        "\n",
        "    if current_context not in plm:\n",
        "        # Safety fallback\n",
        "        current_context = random.choice(list(plm.keys()))\n",
        "\n",
        "    # Get the log probability distribution for next words\n",
        "    next_word_log_dist = plm[current_context]\n",
        "\n",
        "    # Convert to lists\n",
        "    tokens = list(next_word_log_dist.keys())\n",
        "    log_probs = list(next_word_log_dist.values())\n",
        "\n",
        "    # Convert log probs to regular probs with numerical stability\n",
        "    max_log_prob = max(log_probs)\n",
        "    probs = [math.exp(lp - max_log_prob) for lp in log_probs]\n",
        "\n",
        "    # Apply temperature for sampling only\n",
        "    if temp != 1.0:\n",
        "        probs_array = np.array(probs, dtype=np.float64)\n",
        "        probs_array = np.clip(probs_array, 1e-12, 1.0)\n",
        "        scaled = np.exp(np.log(probs_array) / temp)\n",
        "        sampling_probs = (scaled / np.sum(scaled)).tolist()\n",
        "    else:\n",
        "        # Just normalize\n",
        "        total = sum(probs)\n",
        "        sampling_probs = [p/total for p in probs]\n",
        "\n",
        "    # Sample next word using temperature-adjusted probabilities\n",
        "    next_word = random.choices(tokens, weights=sampling_probs)[0]\n",
        "\n",
        "    # Get the true log probability (not temperature-adjusted) for scoring\n",
        "    word_index = tokens.index(next_word)\n",
        "    true_log_prob = log_probs[word_index]\n",
        "\n",
        "    return next_word, true_log_prob, current_context\n",
        "\n",
        "# Test\n",
        "test_context = ('<s>', 'the')\n",
        "print(f\"Testing with context {test_context}:\\n\")\n",
        "for i in range(5):\n",
        "    word, log_p, ctx = get_next_word_with_log_prob(test_context, plm, temp=1.0)\n",
        "    print(f\"  Word: {word:15s} | Log P: {log_p:.4f} | Context used: {ctx}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modified sentence generator that tracks perplexity\n",
        "\n",
        "# Generate a sentence using N-gram model with backoff and temperature.\n",
        "# Returns: (tokens, perplexity)\n",
        "# - tokens: list of tokens including <s> and </s>\n",
        "# - perplexity: the perplexity of the generated sentence\n",
        "def get_sentence_with_perplexity(plm, N=3, temp=1.0, max_len=100):\n",
        "    tokens = ['<s>']\n",
        "    sum_log_probs = 0.0\n",
        "\n",
        "    while tokens[-1] != '</s>' and len(tokens) < max_len:\n",
        "        # Determine left context size based on current sentence length\n",
        "        context_size = min(N - 1, len(tokens))\n",
        "        lcontext = tuple(tokens[-context_size:]) if context_size > 0 else tuple()\n",
        "\n",
        "        # Get next word with its true log probability\n",
        "        next_word, true_log_prob, context_used = get_next_word_with_log_prob(lcontext, plm, temp=temp)\n",
        "\n",
        "        # Update running sum with true log probability\n",
        "        sum_log_probs += true_log_prob\n",
        "\n",
        "        # Append token\n",
        "        tokens.append(next_word)\n",
        "\n",
        "    # Calculate ALP and perplexity\n",
        "    # we divide by (len(tokens) - 1) because we don't count the first <s> token\n",
        "    n_predicted = len(tokens) - 1  # Number of tokens predicted (excluding first <s>)\n",
        "\n",
        "    if n_predicted > 0:\n",
        "        alp = sum_log_probs / n_predicted\n",
        "        perplexity = np.exp(-alp)\n",
        "    else:\n",
        "        perplexity = float('inf')\n",
        "\n",
        "    return tokens, perplexity\n",
        "\n",
        "\n",
        "print(\"Testing sentence generation with perplexity calculation:\\n\")\n",
        "for i in range(5):\n",
        "    sent, pp = get_sentence_with_perplexity(plm, N=3, temp=1.0)\n",
        "    print(f\"Sentence {i+1} (PP={pp:.2f}):\")\n",
        "    print_sentence(sent)\n",
        "    print()"
      ],
      "metadata": {
        "id": "8ui3yxkbNtkV",
        "outputId": "aa49514f-39c3-4687-b5a6-e527bb41d8e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing sentence generation with perplexity calculation:\n",
            "\n",
            "Sentence 1 (PP=1.21):\n",
            "Rachel said that schools and synagogues occupied most of the behavior pattern of population masses were compared to scientific discoveries concerning the motion- pattern of population masses were compared to scientific discoveries concerning the motion- pattern of population masses were compared to scientific discoveries concerning the motion- pattern of gaseous masses.\n",
            "\n",
            "Sentence 2 (PP=1.26):\n",
            "Three days had passed since spencer's arrest and each day had brought new dangers, new fears.\n",
            "\n",
            "Sentence 3 (PP=4.64):\n",
            "13.\n",
            "\n",
            "Sentence 4 (PP=1.67):\n",
            "Andrei remembered a bathyran meeting long ago.\n",
            "\n",
            "Sentence 5 (PP=1.24):\n",
            "It is suggested that in many respects the horse lung may be, shall find that any person is entitled to any such payment shall have been sitting with a broad grin on your face all evening.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 1: Temperature = 0.2 with perplexity\n",
        "\n",
        "print(\"EXPERIMENT 1: Temperature = 0.2 (Low - focused, deterministic)\")\n",
        "print(\"-\" * 60)\n",
        "print()\n",
        "\n",
        "temperature = 0.2\n",
        "results_temp_02 = []\n",
        "\n",
        "for i in range(10):\n",
        "    sent, pp = get_sentence_with_perplexity(plm, N=3, temp=temperature)\n",
        "    results_temp_02.append((sent, pp))\n",
        "    print(f\"Sentence {i+1} (Perplexity = {pp:.2f}):\")\n",
        "    print_sentence(sent)\n",
        "    print()\n",
        "\n",
        "# Calculate average perplexity\n",
        "avg_pp_02 = np.mean([pp for _, pp in results_temp_02])\n",
        "print(f\"Average Perplexity for temp=0.2: {avg_pp_02:.2f}\")\n",
        "print()"
      ],
      "metadata": {
        "id": "JKiS40NeOVZH",
        "outputId": "f383ca19-921a-4a2a-fb0e-a39372226d23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXPERIMENT 1: Temperature = 0.2 (Low - focused, deterministic)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Sentence 1 (Perplexity = 1.19):\n",
            "The genuinely interesting question, then, becomes: what factors determine the degree of realism or distortion in conventional images of jews??\n",
            "\n",
            "Sentence 2 (Perplexity = 1.70):\n",
            "The most prominent magazine illustrators in america;;\n",
            "\n",
            "Sentence 3 (Perplexity = 1.85):\n",
            "He was one of the human than any other presently known species.\n",
            "\n",
            "Sentence 4 (Perplexity = 1.41):\n",
            "The belgians were interested primarily in the philippines have demonstrated that transitional societies can work toward balanced national development.\n",
            "\n",
            "Sentence 5 (Perplexity = 1.26):\n",
            "The president knew that a confrontation with mr. khrushchev sooner or later probably was inevitable and even desirable.\n",
            "\n",
            "Sentence 6 (Perplexity = 1.42):\n",
            "The latter now furnishes the area with electricity distributed from a metaphysical point of view, the former superior court judge said.\n",
            "\n",
            "Sentence 7 (Perplexity = 1.27):\n",
            "The favorite excuse of those who have now recanted their approval of communism is that they also learn to readjust to society.\n",
            "\n",
            "Sentence 8 (Perplexity = 1.70):\n",
            "He was not a new experience to ekstrohm.\n",
            "\n",
            "Sentence 9 (Perplexity = 1.29):\n",
            "The favorite excuse of those who have now recanted their approval of communism is that they did not know how things would develop.\n",
            "\n",
            "Sentence 10 (Perplexity = 1.39):\n",
            "The grateful way she looked at morgan made him ashamed of himself.\n",
            "\n",
            "Average Perplexity for temp=0.2: 1.45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2: Temperature = 1.0 with perplexity\n",
        "\n",
        "print(\"EXPERIMENT 2: Temperature = 1.0 (Balanced)\")\n",
        "print(\"-\" * 50)\n",
        "print()\n",
        "\n",
        "temperature = 1.0\n",
        "results_temp_10 = []\n",
        "\n",
        "for i in range(10):\n",
        "    sent, pp = get_sentence_with_perplexity(plm, N=3, temp=temperature)\n",
        "    results_temp_10.append((sent, pp))\n",
        "    print(f\"Sentence {i+1} (Perplexity = {pp:.2f}):\")\n",
        "    print_sentence(sent)\n",
        "    print()\n",
        "\n",
        "# Calculate average perplexity\n",
        "avg_pp_10 = np.mean([pp for _, pp in results_temp_10])\n",
        "print(f\"Average Perplexity for temp=1.0: {avg_pp_10:.2f}\")\n",
        "print()"
      ],
      "metadata": {
        "id": "nDITmX3IOYbF",
        "outputId": "16ad47a3-f941-4620-c60d-600cdaa6f03a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXPERIMENT 2: Temperature = 1.0 (Balanced)\n",
            "--------------------------------------------------\n",
            "\n",
            "Sentence 1 (Perplexity = 1.46):\n",
            "High school students have more sense of the ruddiness was gone from his face and he stared at ramey.\n",
            "\n",
            "Sentence 2 (Perplexity = 1.50):\n",
            "He swore, and other property or rights by purchase, license, lease, or employees with respect to such payment.\n",
            "\n",
            "Sentence 3 (Perplexity = 1.52):\n",
            "Opposite the number 1105 stood one word: unoccupied.\n",
            "\n",
            "Sentence 4 (Perplexity = 1.43):\n",
            "Writes: does numbness in the philippines have demonstrated that transitional societies can work toward balanced national development.\n",
            "\n",
            "Sentence 5 (Perplexity = 1.28):\n",
            "As autumn starts its annual sweep, few americans and canadians realize how fortunate they are free from the necessity of manipulating objects;;\n",
            "\n",
            "Sentence 6 (Perplexity = 1.43):\n",
            "There are now 162,400 miles of roads and 106,500 miles of supplemental foot and horse trails.\n",
            "\n",
            "Sentence 7 (Perplexity = 1.57):\n",
            "Rachel said that schools and synagogues occupied most of the order of merit of the`` let me stay and take the pictures you wanted, mamma.\n",
            "\n",
            "Sentence 8 (Perplexity = 1.79):\n",
            "I mean I've got to -- to see to the kitchen.\n",
            "\n",
            "Sentence 9 (Perplexity = 1.62):\n",
            "Check the quality of the congo, which is rich in copper, tin, cobalt, manganese, zinc, and the transom.\n",
            "\n",
            "Sentence 10 (Perplexity = 1.26):\n",
            "Three days had passed since spencer's arrest and each day had brought new dangers, new fears.\n",
            "\n",
            "Average Perplexity for temp=1.0: 1.49\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 3: Temperature = 5.0 with perplexity\n",
        "\n",
        "print(\"EXPERIMENT 3: Temperature = 5.0 (High - random, creative)\")\n",
        "print(\"-\" * 60)\n",
        "print()\n",
        "\n",
        "temperature = 5.0\n",
        "results_temp_50 = []\n",
        "\n",
        "for i in range(10):\n",
        "    sent, pp = get_sentence_with_perplexity(plm, N=3, temp=temperature)\n",
        "    results_temp_50.append((sent, pp))\n",
        "    print(f\"Sentence {i+1} (Perplexity = {pp:.2f}):\")\n",
        "    print_sentence(sent)\n",
        "    print()\n",
        "\n",
        "# Calculate average perplexity\n",
        "avg_pp_50 = np.mean([pp for _, pp in results_temp_50])\n",
        "print(f\"Average Perplexity for temp=5.0: {avg_pp_50:.2f}\")\n",
        "print()"
      ],
      "metadata": {
        "id": "YgAKdpsdOa81",
        "outputId": "39aba995-bfef-4a4f-adc8-391b1fd90dad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXPERIMENT 3: Temperature = 5.0 (High - random, creative)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Sentence 1 (Perplexity = 1.39):\n",
            "Calloused fingers, caressed only by the united states, as pentagon mutterers labeled it, apparently was a post of honor, held inviolate for him;;\n",
            "\n",
            "Sentence 2 (Perplexity = 1.58):\n",
            "`` well, no'', the new country the electoral process is considered as a means of resolving fundamental, and gradually his listeners warmed to him.\n",
            "\n",
            "Sentence 3 (Perplexity = 1.30):\n",
            "Plank the sides first, using glue and one- inch, no. 12 stronghold nails at all battens, the former superior court judge said.\n",
            "\n",
            "Sentence 4 (Perplexity = 1.36):\n",
            "Theories of the eternal plan, that man's ambition when linked with God would be a driving, indefatigable force for good in the church today stands in the left hand at night, which is rich in copper, tin, cobalt, manganese, zinc, and the outcome may mean the difference between life or death, or at least serious injuries, for many veterans.\n",
            "\n",
            "Sentence 5 (Perplexity = 1.26):\n",
            "Three days had passed since spencer's arrest and each day had brought new dangers, new fears.\n",
            "\n",
            "Sentence 6 (Perplexity = 3.16):\n",
            "Soccer club.\n",
            "\n",
            "Sentence 7 (Perplexity = 1.45):\n",
            "China never tried to shut out the noise, turbulence around the vehicle, etc..\n",
            "\n",
            "Sentence 8 (Perplexity = 3.16):\n",
            "Mr. mccormack.\n",
            "\n",
            "Sentence 9 (Perplexity = 1.67):\n",
            "Andrei remembered a bathyran meeting long ago.\n",
            "\n",
            "Sentence 10 (Perplexity = 2.11):\n",
            "To know how things would develop.\n",
            "\n",
            "Average Perplexity for temp=5.0: 1.84\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary comparison\n",
        "\n",
        "print(\"Perplexity Comparison Across Temperatures\")\n",
        "print(\"-\" * 45)\n",
        "print()\n",
        "print(f\"Temperature 0.2: Average Perplexity = {avg_pp_02:.2f}\")\n",
        "print(f\"Temperature 1.0: Average Perplexity = {avg_pp_10:.2f}\")\n",
        "print(f\"Temperature 5.0: Average Perplexity = {avg_pp_50:.2f}\")"
      ],
      "metadata": {
        "id": "c79if3AyOdSY",
        "outputId": "a821c5d2-45e2-4e2e-9362-7aed25583195",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity Comparison Across Temperatures\n",
            "---------------------------------------------\n",
            "\n",
            "Temperature 0.2: Average Perplexity = 1.45\n",
            "Temperature 1.0: Average Perplexity = 1.49\n",
            "Temperature 5.0: Average Perplexity = 1.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the sentence with lowest perplexity across all temperatures\n",
        "\n",
        "all_results = results_temp_02 + results_temp_10 + results_temp_50\n",
        "\n",
        "# Sort by perplexity (lower the better)\n",
        "sorted_results = sorted(all_results, key=lambda x: x[1])\n",
        "\n",
        "print(\"TOP 10 SENTENCES BY PERPLEXITY\")\n",
        "print(\"-\" * 40)\n",
        "print()\n",
        "\n",
        "for i, (sent, pp) in enumerate(sorted_results[:10]):\n",
        "    print(f\"Rank {i+1} (Perplexity = {pp:.2f}):\")\n",
        "    print_sentence(sent)\n",
        "    print()\n",
        "\n",
        "# Set a3a to the best sentence (lowest perplexity)\n",
        "best_sent, best_pp = sorted_results[0]\n",
        "a3a = print_sentence(best_sent, do_print=False)\n",
        "\n",
        "print(f\"Best sentence (lowest perplexity = {best_pp:.2f}):\")\n",
        "print(f\"a3a = '{a3a}'\")"
      ],
      "metadata": {
        "id": "qgXPHQ2pOiTA",
        "outputId": "63af2860-7cf2-4b00-ea13-03038fc647b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOP 10 SENTENCES BY PERPLEXITY\n",
            "----------------------------------------\n",
            "\n",
            "Rank 1 (Perplexity = 1.19):\n",
            "The genuinely interesting question, then, becomes: what factors determine the degree of realism or distortion in conventional images of jews??\n",
            "\n",
            "Rank 2 (Perplexity = 1.26):\n",
            "The president knew that a confrontation with mr. khrushchev sooner or later probably was inevitable and even desirable.\n",
            "\n",
            "Rank 3 (Perplexity = 1.26):\n",
            "Three days had passed since spencer's arrest and each day had brought new dangers, new fears.\n",
            "\n",
            "Rank 4 (Perplexity = 1.26):\n",
            "Three days had passed since spencer's arrest and each day had brought new dangers, new fears.\n",
            "\n",
            "Rank 5 (Perplexity = 1.27):\n",
            "The favorite excuse of those who have now recanted their approval of communism is that they also learn to readjust to society.\n",
            "\n",
            "Rank 6 (Perplexity = 1.28):\n",
            "As autumn starts its annual sweep, few americans and canadians realize how fortunate they are free from the necessity of manipulating objects;;\n",
            "\n",
            "Rank 7 (Perplexity = 1.29):\n",
            "The favorite excuse of those who have now recanted their approval of communism is that they did not know how things would develop.\n",
            "\n",
            "Rank 8 (Perplexity = 1.30):\n",
            "Plank the sides first, using glue and one- inch, no. 12 stronghold nails at all battens, the former superior court judge said.\n",
            "\n",
            "Rank 9 (Perplexity = 1.36):\n",
            "Theories of the eternal plan, that man's ambition when linked with God would be a driving, indefatigable force for good in the church today stands in the left hand at night, which is rich in copper, tin, cobalt, manganese, zinc, and the outcome may mean the difference between life or death, or at least serious injuries, for many veterans.\n",
            "\n",
            "Rank 10 (Perplexity = 1.39):\n",
            "The grateful way she looked at morgan made him ashamed of himself.\n",
            "\n",
            "Best sentence (lowest perplexity = 1.19):\n",
            "a3a = 'The genuinely interesting question, then, becomes: what factors determine the degree of realism or distortion in conventional images of jews??'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86s5mCOG4tsx"
      },
      "source": [
        "### Graded Questions:\n",
        "\n",
        "#### Part 3A: In the next cell, set `a3a` to the sentence with the smallest perplexity. Use `print_sentence(..., do_print=False)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "O7YFYl_Q4tsx"
      },
      "outputs": [],
      "source": [
        "# Your answer here\n",
        "\n",
        "a3a = print_sentence(best_sent, do_print=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "fVVfD2wU4tsx",
        "outputId": "48c514dd-3d9b-473d-8073-334b7c94fcbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a3a = The genuinely interesting question, then, becomes: what factors determine the degree of realism or distortion in conventional images of jews??\n"
          ]
        }
      ],
      "source": [
        "# Graded Answer\n",
        "# DO NOT change this cell in any way and do not make any other assignments to variable a3a\n",
        "print(f'a3a = {a3a}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXpwNPeh4tsx"
      },
      "source": [
        "#### Part 3B:  Set `a3b` to the perplexity for the sentence you provided in Part 3A.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "RWOpVhIj4tsx"
      },
      "outputs": [],
      "source": [
        "# Your answer here\n",
        "\n",
        "a3b = 1.19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "sq34mClR4tsx",
        "outputId": "684f85af-b1ed-4f6e-b526-8718f70a1ccf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a3b = 1.19\n"
          ]
        }
      ],
      "source": [
        "# Graded Answer\n",
        "# DO NOT change this cell in any way and do not make any other assignments to variable a1 in this problem\n",
        "\n",
        "print(f'a3b = {a3b}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO3oK2t34tsx"
      },
      "source": [
        "#### Part 3C:  Describe in a few sentences what you observed with the different temperature settings (and try more if you wish!). Which produces the sentences with the best perplexity (you might want to take the average of all 10!).\n",
        "\n",
        "Your answer here:\n",
        "The temperature 0.2 (low) produced the most focused and deterministic outputs with the lowest average perplexity. The sentences were coherent and stayed close to high-probability paths through the model. Some sentences repeated (for example: \"The favorite excuse...\" appeared\n",
        "twice), indicating the model was consistently choosing the most probable continuations. The average perplexity is 1.45.\n",
        "The Temperature 1.0 (balanced) maintained the model's original probability distribution and produced slightly higher perplexity than temp = 0.2. The sentences were diverse and natural with good balance between coherence and variety. This represents \"true\" sampling from the model without any probability reshaping. The average perplexity was 1.49.\n",
        "This temperature 5.0 (High) produced the highest average perplexity, indicating the generated sentences were less typical under the model's learned distribution. While still mostly coherent, the model explored more unlikely word combinations, resulting in more creative but occasionally awkward constructions.The average perplexity was 1.60.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfFsUCp74tsx"
      },
      "source": [
        "## Problem Four:  Beam Search\n",
        "\n",
        "For our final problem, we'll implement a common technique for searching for sentences with low perplexity.\n",
        "\n",
        "**Beam search** is a pragmatic middle ground between **greedy decoding** (pick the single best next word each step) and **exhaustive search** (try all sequences).\n",
        "\n",
        "![Screenshot 2025-10-04 at 12.12.48 PM.png](attachment:224d4777-a5b9-4360-9cc3-5651367faeb0.png)\n",
        "\n",
        "The basic idea is reasonably simple:\n",
        "\n",
        "Maintain a list of at most **B** incomplete sentences, sorted in **decreasing order of their ALP (best at the top)**; you'll need to calculate this during the sort, or perhaps store a triple\n",
        "> (list-of-tokens, sum-of-log-probs, ALP-so-far)\n",
        "\n",
        "where\n",
        "> ALP-so-far =sum-of-log-probs/(len(list-of-tokens)-1)\n",
        "\n",
        "**In detail:**\n",
        "\n",
        "Initialize a priority queue `PQ = [ ['<s>'],0.0] ]`\n",
        "\n",
        "1. In each loop:\n",
        "    - Generate **C** continuations of each of the partial sentences in the queue **PQ** (optional but useful: remove duplicates)\n",
        "    - Remove any completed sentences, calculate their perplexity and store them in a separate list `Finished`.\n",
        "    - Sort the list of remaining continuations and delete all but the best **B** candidates.\n",
        "    - Replace **PQ** with this list of new candidates.\n",
        "3. Repeat from step 1 until you get 10 finished sentences in `Finished` or simply iterate 100 times.  \n",
        "4. Sort the list `Finished` in increasing order of perplexity and print it out.\n",
        "\n",
        "  This preserves multiple promising continuations (unlike greedy), but avoids the combinatorial blow-up of exhaustive search. Using **log-probs** makes scoring stable; using a **length-normalized** score (ALP) prevents the search from favoring short fragments. Beam width (B) controls the trade-off: larger (B) explores more but costs more time and can still prune good paths too early. Continuation width (C) controls how widely you search possible continuations, and uses temperature.\n",
        "\n",
        "**ToDo:**\n",
        "\n",
        "- Implement beam search as described, using $B=C=5$.\n",
        "- Experiment with temperatures of 0.2, 1.0, and 5.0 as before.\n",
        "- Print out your finished sentences with perplexities.\n",
        "- Answer the graded questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "PNCd8dKU4tsx",
        "outputId": "a7a01598-855b-4495-d41a-557b82dcd5eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing beam search with B=5, C=5, temp=1.0:\n",
            "\n",
            "Rank 1 (Perplexity = 1.2592):\n",
            "As autumn starts its annual sweep, few americans and canadians realize how fortunate they are in having the world's finest fall coloring.\n",
            "\n",
            "Rank 2 (Perplexity = 1.2789):\n",
            "As autumn starts its annual sweep, few americans and canadians realize how fortunate they are free from the necessity of manipulating objects;;\n",
            "\n",
            "Rank 3 (Perplexity = 1.3130):\n",
            "As autumn starts its annual sweep, few americans and canadians realize how fortunate they are in having the world.\n",
            "\n",
            "Rank 4 (Perplexity = 1.3207):\n",
            "As autumn starts its annual sweep, few americans and canadians realize how fortunate they are free from the farm buildings.\n",
            "\n",
            "Rank 5 (Perplexity = 1.5029):\n",
            "It was a post of honor, held inviolate for him;;\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code here; add as many cells as you wish\n",
        "# Beam Search Implementation\n",
        "\n",
        "# Beam search to find low-perplexity sentences.\n",
        "# Parameters:\n",
        "# - plm: probability language model\n",
        "# - N: N-gram order (3 for trigrams)\n",
        "# - B: beam width (number of candidates to keep)\n",
        "# - C: continuation width (number of continuations per candidate)\n",
        "# - temp: temperature for sampling\n",
        "# - max_iterations: maximum number of iterations\n",
        "# - target_sentences: stop when we have this many finished sentences\n",
        "# Returns:\n",
        "# - List of (tokens, perplexity) tuples sorted by perplexity\n",
        "\n",
        "def beam_search(plm, N=3, B=5, C=5, temp=1.0, max_iterations=100, target_sentences=10):\n",
        "    # Priority queue: list of (tokens, sum_log_probs, alp)\n",
        "    # where alp = sum_log_probs / (len(tokens) - 1)\n",
        "    pq = [(['<s>'], 0.0, 0.0)]  # (tokens, sum_log_probs, alp)\n",
        "    finished = []\n",
        "\n",
        "    for iteration in range(max_iterations):\n",
        "        if len(finished) >= target_sentences:\n",
        "            break\n",
        "\n",
        "        # Generate C continuations for each candidate in PQ\n",
        "        candidates = []\n",
        "\n",
        "        for tokens, sum_log_probs, _ in pq:\n",
        "            # Skip if finished\n",
        "            if tokens[-1] == '</s>':\n",
        "                continue\n",
        "\n",
        "            # Determine left context\n",
        "            context_size = min(N - 1, len(tokens))\n",
        "            lcontext = tuple(tokens[-context_size:]) if context_size > 0 else tuple()\n",
        "\n",
        "            # Generate C continuations\n",
        "            for _ in range(C):\n",
        "                next_word, true_log_prob, context_used = get_next_word_with_log_prob(\n",
        "                    lcontext, plm, temp=temp\n",
        "                )\n",
        "\n",
        "                # Create new candidate\n",
        "                new_tokens = tokens + [next_word]\n",
        "                new_sum = sum_log_probs + true_log_prob\n",
        "                # Don't count first <s>\n",
        "                new_alp = new_sum / (len(new_tokens) - 1)\n",
        "\n",
        "                candidates.append((new_tokens, new_sum, new_alp))\n",
        "\n",
        "        # Remove duplicates (same token sequence)\n",
        "        # Convert to tuple for hashing\n",
        "        unique_candidates = {}\n",
        "        for tokens, sum_lp, alp in candidates:\n",
        "            key = tuple(tokens)\n",
        "            if key not in unique_candidates:\n",
        "                unique_candidates[key] = (tokens, sum_lp, alp)\n",
        "\n",
        "        candidates = list(unique_candidates.values())\n",
        "\n",
        "        # Separate finished from unfinished\n",
        "        new_pq = []\n",
        "        for tokens, sum_lp, alp in candidates:\n",
        "            if tokens[-1] == '</s>':\n",
        "                # Calculate final perplexity\n",
        "                n_predicted = len(tokens) - 1\n",
        "                final_alp = sum_lp / n_predicted\n",
        "                perplexity = np.exp(-final_alp)\n",
        "                finished.append((tokens, perplexity))\n",
        "            else:\n",
        "                new_pq.append((tokens, sum_lp, alp))\n",
        "\n",
        "        # Sort by ALP (higher is better, so reverse)\n",
        "        new_pq.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "        # Keep only top B candidates\n",
        "        pq = new_pq[:B]\n",
        "\n",
        "        # Stop if no more candidates\n",
        "        if len(pq) == 0:\n",
        "            break\n",
        "\n",
        "    # Sort finished sentences by perplexity (lower is better)\n",
        "    finished.sort(key=lambda x: x[1])\n",
        "\n",
        "    return finished\n",
        "\n",
        "print(\"Testing beam search with B=5, C=5, temp=1.0:\")\n",
        "print()\n",
        "test_results = beam_search(plm, N=3, B=5, C=5, temp=1.0, max_iterations=50, target_sentences=5)\n",
        "\n",
        "for i, (tokens, pp) in enumerate(test_results[:5]):\n",
        "    print(f\"Rank {i+1} (Perplexity = {pp:.4f}):\")\n",
        "    print_sentence(tokens)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 1: Beam Search with Temperature = 0.2\n",
        "print(\"Beam Search - Temperature = 0.2 (Low)\")\n",
        "print(\"B=5, C=5\")\n",
        "print(\"-\" * 80)\n",
        "print()\n",
        "\n",
        "results_beam_02 = beam_search(plm, N=3, B=5, C=5, temp=0.2, max_iterations=100, target_sentences=10)\n",
        "\n",
        "print(f\"Found {len(results_beam_02)} sentences\\n\")\n",
        "print(\"Top 10 sentences by perplexity:\")\n",
        "print()\n",
        "\n",
        "for i, (tokens, pp) in enumerate(results_beam_02[:10]):\n",
        "    print(f\"Rank {i+1} (Perplexity = {pp:.4f}):\")\n",
        "    print_sentence(tokens)\n",
        "    print()\n",
        "\n",
        "if len(results_beam_02) > 0:\n",
        "    avg_pp = np.mean([pp for _, pp in results_beam_02[:10]])\n",
        "    print(f\"Average perplexity (top 10): {avg_pp:.4f}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "4EcCoyryTfpe",
        "outputId": "8704eb1a-a67b-42aa-95f6-e18d8f6eb85f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam Search - Temperature = 0.2 (Low)\n",
            "B=5, C=5\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Found 10 sentences\n",
            "\n",
            "Top 10 sentences by perplexity:\n",
            "\n",
            "Rank 1 (Perplexity = 1.2589):\n",
            "The president knew that a confrontation with mr. khrushchev sooner or later probably was inevitable and even desirable.\n",
            "\n",
            "Rank 2 (Perplexity = 1.3688):\n",
            "`` we must keep the bloodstream of new jersey clean'', watching to see that they do not break their parole and that they also learn to readjust to society.\n",
            "\n",
            "Rank 3 (Perplexity = 1.3895):\n",
            "The grateful way she looked at morgan made him ashamed of himself.\n",
            "\n",
            "Rank 4 (Perplexity = 1.4236):\n",
            "`` let me stay and take the pictures you wanted, mamma.\n",
            "\n",
            "Rank 5 (Perplexity = 1.4452):\n",
            "`` we must keep the bloodstream of new jersey clean'', watching to see that they also learn to readjust to society.\n",
            "\n",
            "Rank 6 (Perplexity = 1.4456):\n",
            "`` we must keep the bloodstream of new jersey clean'', watching to see in paris a year ago.\n",
            "\n",
            "Rank 7 (Perplexity = 1.4627):\n",
            "`` we must keep the bloodstream of new jersey clean'', watching to see that they did not know how things would develop.\n",
            "\n",
            "Rank 8 (Perplexity = 1.6728):\n",
            "`` we must keep the bloodstream of new jersey clean'', the other the villain.\n",
            "\n",
            "Rank 9 (Perplexity = 1.7690):\n",
            "`` we must keep the bloodstream of new jersey in the closet.\n",
            "\n",
            "Rank 10 (Perplexity = 1.9512):\n",
            "`` mother'', herr schaffner said.\n",
            "\n",
            "Average perplexity (top 10): 1.5188\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2: Beam Search with Temperature = 1.0\n",
        "print(\"Beam Search - Temperature = 1.0 (Balanced)\")\n",
        "print(\"B=5, C=5\")\n",
        "print(\"-\" * 80)\n",
        "print()\n",
        "\n",
        "results_beam_10 = beam_search(plm, N=3, B=5, C=5, temp=1.0, max_iterations=100, target_sentences=10)\n",
        "\n",
        "print(f\"Found {len(results_beam_10)} sentences\\n\")\n",
        "print(\"Top 10 sentences by perplexity:\")\n",
        "print()\n",
        "\n",
        "for i, (tokens, pp) in enumerate(results_beam_10[:10]):\n",
        "    print(f\"Rank {i+1} (Perplexity = {pp:.4f}):\")\n",
        "    print_sentence(tokens)\n",
        "    print()\n",
        "\n",
        "if len(results_beam_10) > 0:\n",
        "    avg_pp = np.mean([pp for _, pp in results_beam_10[:10]])\n",
        "    print(f\"Average perplexity (top 10): {avg_pp:.4f}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "YoUiyJlETjpr",
        "outputId": "0ddbeb3f-7148-4637-cb80-7bc9386363b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam Search - Temperature = 1.0 (Balanced)\n",
            "B=5, C=5\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Found 10 sentences\n",
            "\n",
            "Top 10 sentences by perplexity:\n",
            "\n",
            "Rank 1 (Perplexity = 1.1923):\n",
            "He was not enthusiastic over the newly acquired claude lorrain, but reminisced with pleasure over a poussin exhibit he had been raids on naples -- but naples was pretty far north on the opposite coast.\n",
            "\n",
            "Rank 2 (Perplexity = 1.2174):\n",
            "Berman, whose fame has rested in recent years on his skills as a night club monologist, proved himself very much at home in musical comedy.\n",
            "\n",
            "Rank 3 (Perplexity = 1.2314):\n",
            "He was not enthusiastic over the newly acquired claude lorrain, but reminisced with pleasure over a poussin exhibit he had been able to see that they did not know how his work would sound when done by professional musicians and by trained voices.\n",
            "\n",
            "Rank 4 (Perplexity = 1.2754):\n",
            "He was not enthusiastic over the newly acquired claude lorrain, but reminisced with pleasure over a poussin exhibit he had been able to see in paris a year ago.\n",
            "\n",
            "Rank 5 (Perplexity = 1.2889):\n",
            "He was not enthusiastic over the newly acquired claude lorrain, but reminisced with pleasure over a poussin exhibit he had been able to see that they also learn to readjust to society.\n",
            "\n",
            "Rank 6 (Perplexity = 1.3047):\n",
            "He was not enthusiastic over the newly acquired claude lorrain, but reminisced with pleasure over a poussin exhibit he had been able to see that they did not know how things would develop.\n",
            "\n",
            "Rank 7 (Perplexity = 1.3300):\n",
            "Berman, whose fame has rested in recent years on his skills as a source of policy guidance.\n",
            "\n",
            "Rank 8 (Perplexity = 1.3876):\n",
            "Efforts such as the case may be, shall find that any person is entitled to any such payment, after such payment.\n",
            "\n",
            "Rank 9 (Perplexity = 1.4016):\n",
            "Efforts such as the case may be, shall find that any person is entitled to any such payment.\n",
            "\n",
            "Rank 10 (Perplexity = 1.7241):\n",
            "He saw the suitcase, which julia was holding.\n",
            "\n",
            "Average perplexity (top 10): 1.3353\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 3: Beam Search with Temperature = 5.0\n",
        "print(\"Beam Search - Temperature = 5.0 (High)\")\n",
        "print(\"B=5, C=5\")\n",
        "print(\"-\" * 80)\n",
        "print()\n",
        "\n",
        "results_beam_50 = beam_search(plm, N=3, B=5, C=5, temp=5.0, max_iterations=100, target_sentences=10)\n",
        "\n",
        "print(f\"Found {len(results_beam_50)} sentences\\n\")\n",
        "print(\"Top 10 sentences by perplexity:\")\n",
        "print()\n",
        "\n",
        "for i, (tokens, pp) in enumerate(results_beam_50[:10]):\n",
        "    print(f\"Rank {i+1} (Perplexity = {pp:.4f}):\")\n",
        "    print_sentence(tokens)\n",
        "    print()\n",
        "\n",
        "if len(results_beam_50) > 0:\n",
        "    avg_pp = np.mean([pp for _, pp in results_beam_50[:10]])\n",
        "    print(f\"Average perplexity (top 10): {avg_pp:.4f}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "nnO5FPLhTnB7",
        "outputId": "a327c31d-7495-413a-a49a-4b56ccf56478",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam Search - Temperature = 5.0 (High)\n",
            "B=5, C=5\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Found 6 sentences\n",
            "\n",
            "Top 10 sentences by perplexity:\n",
            "\n",
            "Rank 1 (Perplexity = 1.2870):\n",
            "After they have developed concepts, they used opaque color throughout, getting solid highlights with active lime white.\n",
            "\n",
            "Rank 2 (Perplexity = 1.3423):\n",
            "Improvement, however, is a mysterious yellowish, waxy substance, chemically a crystalline alcohol.\n",
            "\n",
            "Rank 3 (Perplexity = 1.4236):\n",
            "Or who undertook to set records for remaining erect on a transoceanic jet.\n",
            "\n",
            "Rank 4 (Perplexity = 1.4497):\n",
            "After they have developed concepts, they are in having the world's finest fall coloring.\n",
            "\n",
            "Rank 5 (Perplexity = 1.6120):\n",
            "After they have developed concepts, they are in having the world.\n",
            "\n",
            "Rank 6 (Perplexity = 4.6416):\n",
            "13.\n",
            "\n",
            "Average perplexity (top 10): 1.9594\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare all results and find the overall best sentence\n",
        "print(\"Beam Search Across All Temperatures\")\n",
        "print(\"-\" * 60)\n",
        "print()\n",
        "\n",
        "all_beam_results = results_beam_02 + results_beam_10 + results_beam_50\n",
        "\n",
        "# Sort by perplexity\n",
        "all_beam_results.sort(key=lambda x: x[1])\n",
        "\n",
        "print(\"Top 10 sentences overall:\")\n",
        "print()\n",
        "\n",
        "for i, (tokens, pp) in enumerate(all_beam_results[:10]):\n",
        "    print(f\"Rank {i+1} (Perplexity = {pp:.4f}):\")\n",
        "    print_sentence(tokens)\n",
        "    print()\n",
        "\n",
        "# Best sentence\n",
        "if len(all_beam_results) > 0:\n",
        "    best_tokens, best_pp = all_beam_results[0]\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Best Sentence: (Perplexity = {best_pp:.4f}):\")\n",
        "    print_sentence(best_tokens)"
      ],
      "metadata": {
        "id": "SIxp2L13Tp_Q",
        "outputId": "46519246-8aa9-445d-fea9-9d7e63374884",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam Search Across All Temperatures\n",
            "------------------------------------------------------------\n",
            "\n",
            "Top 10 sentences overall:\n",
            "\n",
            "Rank 1 (Perplexity = 1.1923):\n",
            "He was not enthusiastic over the newly acquired claude lorrain, but reminisced with pleasure over a poussin exhibit he had been raids on naples -- but naples was pretty far north on the opposite coast.\n",
            "\n",
            "Rank 2 (Perplexity = 1.2174):\n",
            "Berman, whose fame has rested in recent years on his skills as a night club monologist, proved himself very much at home in musical comedy.\n",
            "\n",
            "Rank 3 (Perplexity = 1.2314):\n",
            "He was not enthusiastic over the newly acquired claude lorrain, but reminisced with pleasure over a poussin exhibit he had been able to see that they did not know how his work would sound when done by professional musicians and by trained voices.\n",
            "\n",
            "Rank 4 (Perplexity = 1.2589):\n",
            "The president knew that a confrontation with mr. khrushchev sooner or later probably was inevitable and even desirable.\n",
            "\n",
            "Rank 5 (Perplexity = 1.2754):\n",
            "He was not enthusiastic over the newly acquired claude lorrain, but reminisced with pleasure over a poussin exhibit he had been able to see in paris a year ago.\n",
            "\n",
            "Rank 6 (Perplexity = 1.2870):\n",
            "After they have developed concepts, they used opaque color throughout, getting solid highlights with active lime white.\n",
            "\n",
            "Rank 7 (Perplexity = 1.2889):\n",
            "He was not enthusiastic over the newly acquired claude lorrain, but reminisced with pleasure over a poussin exhibit he had been able to see that they also learn to readjust to society.\n",
            "\n",
            "Rank 8 (Perplexity = 1.3047):\n",
            "He was not enthusiastic over the newly acquired claude lorrain, but reminisced with pleasure over a poussin exhibit he had been able to see that they did not know how things would develop.\n",
            "\n",
            "Rank 9 (Perplexity = 1.3300):\n",
            "Berman, whose fame has rested in recent years on his skills as a source of policy guidance.\n",
            "\n",
            "Rank 10 (Perplexity = 1.3423):\n",
            "Improvement, however, is a mysterious yellowish, waxy substance, chemically a crystalline alcohol.\n",
            "\n",
            "--------------------------------------------------\n",
            "Best Sentence: (Perplexity = 1.1923):\n",
            "He was not enthusiastic over the newly acquired claude lorrain, but reminisced with pleasure over a poussin exhibit he had been raids on naples -- but naples was pretty far north on the opposite coast.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare beam search to random sampling\n",
        "print(\"Beam Search vs Random Sampling\")\n",
        "print(\"-\" * 50)\n",
        "print()\n",
        "\n",
        "# Get best from beam search\n",
        "beam_best_pp = all_beam_results[0][1] if len(all_beam_results) > 0 else float('inf')\n",
        "\n",
        "# Get best from random sampling (from Problem 3)\n",
        "all_random_results = results_temp_02 + results_temp_10 + results_temp_50\n",
        "random_best_pp = min([pp for _, pp in all_random_results])\n",
        "\n",
        "print(f\"Best perplexity from Beam Search:    {beam_best_pp:.4f}\")\n",
        "print(f\"Best perplexity from Random Sampling: {random_best_pp:.4f}\")\n",
        "print()\n",
        "\n",
        "if beam_best_pp < random_best_pp:\n",
        "    improvement = ((random_best_pp - beam_best_pp) / random_best_pp) * 100\n",
        "    print(f\"Beam search found a sentence with {improvement:.1f}% lower perplexity\")\n",
        "else:\n",
        "    print(\"Random sampling found equally good or better sentences\")"
      ],
      "metadata": {
        "id": "XRAM3OW8T0f5",
        "outputId": "d66b2b15-8085-4a46-adc2-9cd55e40ab8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam Search vs Random Sampling\n",
            "--------------------------------------------------\n",
            "\n",
            "Best perplexity from Beam Search:    1.1923\n",
            "Best perplexity from Random Sampling: 1.1938\n",
            "\n",
            "Beam search found a sentence with 0.1% lower perplexity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z94lBRmW4tsx"
      },
      "source": [
        "### Graded Questions:\n",
        "\n",
        "#### Part 4A: In the next cell, set `a4a` to the sentence with the smallest perplexity generated by beam search. Use `print_sentence(..., do_print=False)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "o11kjX5i4tsx"
      },
      "outputs": [],
      "source": [
        "# Your answer here\n",
        "# Find the best sentence from beam search\n",
        "if len(all_beam_results) > 0:\n",
        "    best_tokens, best_pp = all_beam_results[0]\n",
        "    a4a = print_sentence(best_tokens, do_print=False)\n",
        "else:\n",
        "    a4a = \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "DJH407P44tsx",
        "outputId": "0efe359c-5b15-45b7-da65-4fb12a3b1955",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a4a = He was not enthusiastic over the newly acquired claude lorrain, but reminisced with pleasure over a poussin exhibit he had been raids on naples -- but naples was pretty far north on the opposite coast.\n"
          ]
        }
      ],
      "source": [
        "# Graded Answer\n",
        "# DO NOT change this cell in any way and do not make any other assignments to variable a3a\n",
        "print(f'a4a = {a4a}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZBewq144tsy"
      },
      "source": [
        "#### Part 4B:  Set `a4b` to the perplexity for the sentence you provided in Part 4A.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "dmSzruLL4tsy"
      },
      "outputs": [],
      "source": [
        "# Your answer here\n",
        "# Get the perplexity from the best sentence\n",
        "if len(all_beam_results) > 0:\n",
        "    best_tokens, best_pp = all_beam_results[0]\n",
        "    a4b = best_pp\n",
        "else:\n",
        "    a4b = float('inf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "ov3garbc4tsy",
        "outputId": "5c7e348e-107d-43db-adcb-cd4354bd7e4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a4b = 1.1923317395780333\n"
          ]
        }
      ],
      "source": [
        "# Graded Answer\n",
        "# DO NOT change this cell in any way and do not make any other assignments to variable a4b in this problem\n",
        "\n",
        "print(f'a4b = {a4b}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nnQk6--4tsy"
      },
      "source": [
        "#### Part 4C:  Describe in a few sentences what you observed with the different temperature settings (and try more if you wish!). Which produces the sentences with the best perplexity (you might want to take the average of all 5!).\n",
        "\n",
        "Your answer here:\n",
        "\n",
        "Beam search with low temperature 0.2 (low) produced many similar sentence beginnings particularly variants starting with \"we must keep the bloodstream of new jersey clean\". The search became somewhat trapped in high-probability paths, leading to repetitive outputs. The best sentence had perplexity 1.2589, which is decent but not the overall best. The average perplexity for the top 10 was 1.5188.\n",
        "The temperature 1.0 (balanced) produced the best results overall. The top sentence achieved perplexity 1.1923, the lowest across all experiments. Beam search found several variations of \"He was not enthusiastic over the newly acquired claude lorrain...\" sentences, exploring different continuations systematically. The diversity was much better than temp = 0.2, with 10 distinct completed sentences found. The average perplexity for the top 10 was 1.3353.\n",
        "The high temperature 5.0 produced the worst results, with only 6 finished sentences found within 100 iterations. The beam search struggled because high temperature flattened the probability\n",
        "distribution too much which made it harder to identify and follow promising paths. The sentences were more diverse but had higher perplexity overall. The average perplexity of the top 10 was 1.9594."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nag7WIEh4tsy"
      },
      "source": [
        "## Appendix One: The Brown Corpus\n",
        "\n",
        "The **Brown Corpus of Standard American English** was compiled at **Brown University** by W. Nelson Francis and Henry Kučera in 1961. It was the **first electronic, balanced corpus of English** ever created and contains about **one million words** drawn from **500 written texts** published in the United States in 1961.\n",
        "\n",
        "At the time, this was groundbreaking: instead of studying isolated examples, linguists and computer scientists could analyze the **statistical properties of language** across many genres. The Brown Corpus became a **benchmark dataset** in early computational linguistics, psycholinguistics, and later in natural language processing.\n",
        "\n",
        "### Genres in the Brown Corpus\n",
        "\n",
        "The 500 texts were divided evenly across **15 categories**, each representing a different register or style of writing:\n",
        "\n",
        "* **Press**: reportage, editorials, reviews\n",
        "* **General prose**: popular lore, belles lettres, essays\n",
        "* **Fiction**: adventure, romance, science fiction, mystery, humor\n",
        "* **Learned writing**: academic and scientific publications\n",
        "* **Religious writing**: sermons, expository texts\n",
        "* **Skills and hobbies**: manuals, do-it-yourself, gardening, sports writing\n",
        "* **Government documents**: official reports, public affairs writing\n",
        "* **Miscellaneous**: popularized non-fiction, biography\n",
        "\n",
        "Each category contributes about 2,000 sentences (roughly 80,000 words), ensuring a **balanced sample** of contemporary written English.\n",
        "\n",
        "### Examples of Source Texts\n",
        "\n",
        "While the Brown Corpus does not preserve full books in sequence, the selections were drawn from published works of the time. Examples include:\n",
        "\n",
        "* **Fiction**: pulp magazines, detective novels, romance stories, humorous fiction.\n",
        "* **Press**: articles from major U.S. newspapers and magazines such as *Time* and *Newsweek*.\n",
        "* **Religion**: sermons, Bible commentary, religious essays.\n",
        "* **Academic**: journal articles in history, sociology, psychology, and linguistics.\n",
        "* **Skills and hobbies**: popular magazines like *Popular Mechanics* and *Field & Stream*.\n",
        "\n",
        "The corpus thus reflects a **snapshot of American English in 1961**: how it was written in popular culture, journalism, science, religion, and government.\n",
        "\n",
        "### Why It Matters\n",
        "\n",
        "* **Historical importance**: the first large corpus, setting the stage for all later corpus linguistics.\n",
        "* **Balanced design**: unlike modern web scrapes (e.g., Wikipedia), Brown was carefully curated to capture a **cross-section of genres**.\n",
        "* **Still used today**: it remains a teaching resource for exploring **word frequencies, n-grams, Zipf’s law, and stylistic differences across genres**.\n",
        "\n",
        "### Categories in the Brown Corpus  \n",
        "\n",
        "The Brown Corpus is divided into 15 genres, each with about 80,000 words (for a total of ~1 million). This balance makes it useful for studying stylistic and lexical variation across English.  \n",
        "\n",
        "| Code | Category              | Description / Examples                                  |\n",
        "|------|-----------------------|---------------------------------------------------------|\n",
        "| A    | Press: Reportage      | Straight news reporting; newspaper and magazine articles |\n",
        "| B    | Press: Editorial      | Opinion pieces and editorials from newspapers/magazines |\n",
        "| C    | Press: Reviews        | Reviews of books, plays, music, films                   |\n",
        "| D    | Religion              | Sermons, religious commentary, Bible studies            |\n",
        "| E    | Skills & Hobbies      | How-to manuals, sports, leisure, do-it-yourself         |\n",
        "| F    | Popular Lore          | Popular science, cultural essays, lore                  |\n",
        "| G    | Belles Lettres        | Literary essays, non-fiction with artistic style        |\n",
        "| H    | Miscellaneous         | Biographies, memoirs, other non-fiction                 |\n",
        "| J    | Learned               | Academic and scientific writing                         |\n",
        "| K    | General Fiction       | Short stories and novels, general fiction               |\n",
        "| L    | Mystery & Detective   | Detective and crime fiction                             |\n",
        "| M    | Science Fiction       | Science fiction stories and novels                      |\n",
        "| N    | Adventure & Western   | Adventure stories, Westerns                             |\n",
        "| P    | Romance               | Romantic fiction                                        |\n",
        "| R    | Humor                 | Humorous fiction and essays                             |\n",
        "\n",
        "Together these categories provide a **snapshot of American English in 1961**, from journalism and government reports to pulp fiction and academic writing.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "kCwhghQ24tsy",
        "outputId": "a270671f-6f1e-4fbc-89cf-fddef9074e9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "-0.6931471805599453\n",
            "-1.0986122886681098\n",
            "-1.3862943611198906\n",
            "-4.605170185988091\n",
            "-23.025850929940457\n"
          ]
        }
      ],
      "source": [
        "for p in [1,1/2,1/3,1/4, 0.01, 1e-10]:\n",
        "          print(math.log(p))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDqss7ca4tsy"
      },
      "source": [
        "## Appendix Two: Using Log-Probabilities in N-Gram Models\n",
        "\n",
        "When working with **n-gram language models**, we calculate the probability of a sentence by multiplying the conditional probabilities of each word:\n",
        "\n",
        "$$\n",
        "P(w_1, w_2, \\dots, w_n) = \\prod_{i=1}^n P(w_i \\mid \\text{context})\n",
        "$$\n",
        "\n",
        "### Do we really need logs for the Brown Corpus?\n",
        "\n",
        "In the Brown Corpus, the **longest sentence has 182 tokens**. That’s not very long compared to modern corpora, so you might think multiplying probabilities directly is fine. For example:\n",
        "\n",
        "* If the average conditional probability were around $0.1$, the longest Brown sentence has probability about\n",
        "  $$(0.1)^{182} = 10^{-182},$$\n",
        "  which is still representable in double precision (smallest positive $\\approx 10^{-324}$).\n",
        "\n",
        "* But if the average probability were closer to $0.01$, then\n",
        "  $$(0.01)^{182} = 10^{-364},$$\n",
        "  which would **underflow to 0**.\n",
        "\n",
        "So in some cases you’d be safe, in others not.\n",
        "\n",
        "### Some Examples of Log Probabilities\n",
        "\n",
        "Since probabilities are always in the range $[0,1.0]$, log probabilities are in the range $[-\\infty,0.0]$. Here are\n",
        "some examples of log probabilities (we'll use natural logs, but the base really doesn't matter):\n",
        "\n",
        "    Probability         Log Probability\n",
        "      1.0                 0.0\n",
        "      1/2                -0.6931471805599453\n",
        "      1/3                -1.0986122886681098\n",
        "      1/4                -1.3862943611198906\n",
        "      0.01               -4.605170185988091\n",
        "      1e-10              -23.025850929940457\n",
        "      1e-1000            -2302.5850929940457\n",
        "\n",
        "(To put this in somewhat real terms, suppose you and a friend could both randomly choose an **atom** somewhere in the observable\n",
        "universe: the probability that you both choose the same atom is approximately 1e-80.)\n",
        "\n",
        "### Why we use log-probabilities anyway\n",
        "\n",
        "Even if underflow is not common in Brown sentences, there are three strong reasons to switch to log-space:\n",
        "\n",
        "1. **Smoothing produces tiny probabilities.** With add-one or Kneser–Ney smoothing, many n-grams have very small values, making underflow more likely.\n",
        "2. **Corpus-level calculations.** Perplexity is often computed over *all tokens* in the corpus. With Brown’s ~1M tokens, multiplying raw probabilities is completely impossible.\n",
        "3. **Consistency with NLP practice.** Modern language models (n-gram and neural alike) always work in log-space. Teaching it here ensures the method scales to larger datasets like Shakespeare, WikiText, or web-scale corpora.\n",
        "\n",
        "### The log-space trick\n",
        "\n",
        "Recall how computing in log-space works:\n",
        "\n",
        "- Convert your numbers to logs\n",
        "- Instead of multiplying, add  \n",
        "- Instead of exponentiation, multiply\n",
        "- If you need to sort, or compare using $\\lt$ or $\\le$, just do it in log-space (since it is monotonic, i.e., preserves order)\n",
        "- Convert back to normal if you want to print it out in human-readable form as a metric or use it with code that expects normal probabilities (e.g., softmax, or sampling).\n",
        "\n",
        "Thus, instead of multiplying probabilities, we sum log probabilities:\n",
        "\n",
        "$$\n",
        "\\log P(w_1, w_2, \\dots, w_n) = \\sum_{i=1}^n \\log P(w_i \\mid \\text{context})\n",
        "$$\n",
        "\n",
        "This prevents underflow, keeps values in a manageable numeric range, and makes computation easier.\n",
        "\n",
        "* **Ranking:** For decoding or beam search, you can use log-probabilities directly, since $\\log$ is monotonic. No conversion back is needed.\n",
        "* **Perplexity:**\n",
        "\n",
        "$$\n",
        "\\text{PP} = \\exp\\left(-\\tfrac{1}{n} \\sum_{i=1}^n \\log P(w_i \\mid \\text{context})\\right)\n",
        "$$\n",
        "\n",
        "Here the exponential is applied only at the end.\n",
        "\n",
        "* **Sampling:** To draw the next word, convert log-probabilities back with `exp()` to normalize.\n",
        "\n",
        "---\n",
        "\n",
        "✅ **TL;DR Summary:** In the Brown Corpus, you *might* get away with raw probabilities for single sentences, but log-space is essential once you apply smoothing, compute perplexity over the whole corpus, or move to larger datasets. It’s also the standard method in NLP, so it’s best to learn it now.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}